import os
import pandas as pd
import json
import re
import nltk
from nltk.corpus import stopwords
from nltk.stem import WordNetLemmatizer
import pymorphy2
from langdetect import detect, LangDetectException

class FileHandler:
    """
    –ö–ª–∞—Å—Å –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –æ–ø–µ—Ä–∞—Ü–∏–π –∑–∞–≥—Ä—É–∑–∫–∏ –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö –∏–∑ —Ñ–∞–π–ª–æ–≤ JSON –∏ CSV.

    –ü—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è–µ—Ç –º–µ—Ç–æ–¥—ã –¥–ª—è —á—Ç–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö –∏–∑ —Ñ–∞–π–ª–æ–≤ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö —Ñ–æ—Ä–º–∞—Ç–æ–≤, —Ç–∞–∫–∏—Ö –∫–∞–∫ JSON –∏ CSV,
    –≤ pandas DataFrame, –∞ —Ç–∞–∫–∂–µ –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è DataFrame –æ–±—Ä–∞—Ç–Ω–æ –≤ —Ñ–∞–π–ª—ã JSON –∏–ª–∏ CSV.
    """
    def __init__(self):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è FileHandler.

        –í—ã–≤–æ–¥–∏—Ç —Å–æ–æ–±—â–µ–Ω–∏–µ –≤ –∫–æ–Ω—Å–æ–ª—å –æ–± —É—Å–ø–µ—à–Ω–æ–π –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ FileHandler.
        """
        print("‚úÖ FileHandler –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω.")

    def load_data(self, path):
        """
        –ó–∞–≥—Ä—É–∂–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –∏–∑ —Ñ–∞–π–ª–∞ JSON –∏–ª–∏ CSV –≤ pandas DataFrame.

        –û–ø—Ä–µ–¥–µ–ª—è–µ—Ç —Ç–∏–ø —Ñ–∞–π–ª–∞ –ø–æ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—é –∏ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–π –º–µ—Ç–æ–¥ pandas –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ –¥–∞–Ω–Ω—ã—Ö.
        –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç —Ñ–∞–π–ª—ã —Å —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—è–º–∏ .json, .csv –∏ .txt.

        –ê—Ä–≥—É–º–µ–Ω—Ç—ã:
            path (str): –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É, –∏–∑ –∫–æ—Ç–æ—Ä–æ–≥–æ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ –∑–∞–≥—Ä—É–∑–∏—Ç—å –¥–∞–Ω–Ω—ã–µ.

        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç:
            pandas.DataFrame: DataFrame, —Å–æ–¥–µ—Ä–∂–∞—â–∏–π –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ.

        –í—ã–∑—ã–≤–∞–µ—Ç:
            FileNotFoundError: –ï—Å–ª–∏ —Ñ–∞–π–ª –ø–æ —É–∫–∞–∑–∞–Ω–Ω–æ–º—É –ø—É—Ç–∏ –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç.
            ValueError: –ï—Å–ª–∏ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ —Ñ–∞–π–ª–∞ –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è.
            Exception: –í —Å–ª—É—á–∞–µ –ª—é–±—ã—Ö –¥—Ä—É–≥–∏—Ö –æ—à–∏–±–æ–∫ –ø—Ä–∏ —á—Ç–µ–Ω–∏–∏ —Ñ–∞–π–ª–∞.

        –í—ã–≤–æ–¥–∏—Ç –≤ –∫–æ–Ω—Å–æ–ª—å —Å–æ–æ–±—â–µ–Ω–∏—è –æ –Ω–∞—á–∞–ª–µ –∑–∞–≥—Ä—É–∑–∫–∏, —É—Å–ø–µ—Ö–µ –∏ –æ—à–∏–±–∫–∞—Ö.
        """
        print(f"üîÑ –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö –∏–∑ —Ñ–∞–π–ª–∞: {path}")
        if not os.path.exists(path):
            print(f"‚ùå –§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {path}")
            raise FileNotFoundError(f"–§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {path}")
        try:
            if path.lower().endswith(".json"):
                with open(path, 'r', encoding='utf-8') as f:
                   data = json.load(f)
                df = pd.DataFrame(data).T
                print(f"‚úÖ –î–∞–Ω–Ω—ã–µ —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω—ã –∏–∑ JSON, —Ñ–æ—Ä–º–∞: {df.shape}")
                return df
            elif path.lower().endswith((".csv", ".txt")):
                df = pd.read_csv(path)
                print(f"‚úÖ –î–∞–Ω–Ω—ã–µ —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω—ã –∏–∑ CSV, —Ñ–æ—Ä–º–∞: {df.shape}")
                return df
            else:
                print(f"‚ùå –ù–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–π —Ñ–æ—Ä–º–∞—Ç —Ñ–∞–π–ª–∞: {path}")
                raise ValueError(f"–ù–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–π —Ñ–æ—Ä–º–∞—Ç —Ñ–∞–π–ª–∞: {path}")
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –¥–∞–Ω–Ω—ã—Ö –∏–∑ {path}: {e}")
            raise

    def save_data(self, df, path):
        """
        –°–æ—Ö—Ä–∞–Ω—è–µ—Ç pandas DataFrame –≤ —Ñ–∞–π–ª JSON –∏–ª–∏ CSV.

        –û–ø—Ä–µ–¥–µ–ª—è–µ—Ç —Ñ–æ—Ä–º–∞—Ç —Ñ–∞–π–ª–∞ –ø–æ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—é –∏ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–π –º–µ—Ç–æ–¥ pandas –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è DataFrame.
        –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç —Ñ–∞–π–ª—ã —Å —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—è–º–∏ .json, .csv –∏ .txt.

        –ê—Ä–≥—É–º–µ–Ω—Ç—ã:
            df (pandas.DataFrame): DataFrame, –∫–æ—Ç–æ—Ä—ã–π –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å.
            path (str): –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É, –≤ –∫–æ—Ç–æ—Ä—ã–π –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –¥–∞–Ω–Ω—ã–µ.

         –í—ã–∑—ã–≤–∞–µ—Ç:
            ValueError: –ï—Å–ª–∏ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ —Ñ–∞–π–ª–∞ –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è.
            Exception: –í —Å–ª—É—á–∞–µ –ª—é–±—ã—Ö –¥—Ä—É–≥–∏—Ö –æ—à–∏–±–æ–∫ –ø—Ä–∏ –∑–∞–ø–∏—Å–∏ —Ñ–∞–π–ª–∞.

        –í—ã–≤–æ–¥–∏—Ç –≤ –∫–æ–Ω—Å–æ–ª—å —Å–æ–æ–±—â–µ–Ω–∏—è –æ –Ω–∞—á–∞–ª–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è, —É—Å–ø–µ—Ö–µ –∏ –æ—à–∏–±–∫–∞—Ö.
        """
        print(f"üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –≤ —Ñ–∞–π–ª: {path}")
        try:
            if path.lower().endswith(".json"):
                df.to_json(path)
                print(f"‚úÖ –î–∞–Ω–Ω—ã–µ —É—Å–ø–µ—à–Ω–æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ JSON, —Ñ–æ—Ä–º–∞: {df.shape}")
            elif path.lower().endswith((".csv", ".txt")):
                df.to_csv(path, index=False)
                print(f"‚úÖ –î–∞–Ω–Ω—ã–µ —É—Å–ø–µ—à–Ω–æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ CSV, —Ñ–æ—Ä–º–∞: {df.shape}")
            else:
                print(f"‚ùå –ù–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–π —Ñ–æ—Ä–º–∞—Ç —Ñ–∞–π–ª–∞: {path}")
                raise ValueError(f"–ù–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–π —Ñ–æ—Ä–º–∞—Ç —Ñ–∞–π–ª–∞: {path}")
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö –≤ {path}: {e}")
            raise


class DataCleaner:
    """
    –ö–ª–∞—Å—Å –¥–ª—è –æ—á–∏—Å—Ç–∫–∏ –∏ –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∏ –Ω–∞–±–æ—Ä–∞ –¥–∞–Ω–Ω—ã—Ö –æ–± –∏–≥—Ä–∞—Ö.

    –ü—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è–µ—Ç –Ω–∞–±–æ—Ä –º–µ—Ç–æ–¥–æ–≤ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ DataFrame, –≤–∫–ª—é—á–∞—è —É–¥–∞–ª–µ–Ω–∏–µ —Å—Ç–æ–ª–±—Ü–æ–≤,
    —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—é —Å—Ç—Ä–æ–∫ –ø–æ —Ä–∞–∑–ª–∏—á–Ω—ã–º –∫—Ä–∏—Ç–µ—Ä–∏—è–º, –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ —Ç–∏–ø–æ–≤ –¥–∞–Ω–Ω—ã—Ö,
    –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ –∏ –æ—á–∏—Å—Ç–∫—É —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö, —Ç–∞–∫–∏—Ö –∫–∞–∫ –æ–ø–∏—Å–∞–Ω–∏—è –∏ —Ç–µ–≥–∏.
    """
    def __init__(self, columns_to_drop=None, min_description_length=30, max_description_length=240, min_tags=3, words_to_remove = ['game', 'world']):
        """
         –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è DataCleaner.

         –ö–æ–Ω—Ñ–∏–≥—É—Ä–∏—Ä—É–µ—Ç –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –æ—á–∏—Å—Ç–∫–∏ –¥–∞–Ω–Ω—ã—Ö, —Ç–∞–∫–∏–µ –∫–∞–∫ —Å–ø–∏—Å–æ–∫ —É–¥–∞–ª—è–µ–º—ã—Ö —Å—Ç–æ–ª–±—Ü–æ–≤,
         –º–∏–Ω–∏–º–∞–ª—å–Ω–∞—è –∏ –º–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –¥–ª–∏–Ω–∞ –æ–ø–∏—Å–∞–Ω–∏–π, –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–µ–≥–æ–≤ –∏ —Å–ø–∏—Å–æ–∫ —Å–ª–æ–≤ –¥–ª—è —É–¥–∞–ª–µ–Ω–∏—è.
         –¢–∞–∫–∂–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ—Ç –ª–µ–º–º–∞—Ç–∏–∑–∞—Ç–æ—Ä—ã –∏ —Å—Ç–æ–ø-—Å–ª–æ–≤–∞ –¥–ª—è –∞–Ω–≥–ª–∏–π—Å–∫–æ–≥–æ –∏ —Ä—É—Å—Å–∫–æ–≥–æ —è–∑—ã–∫–æ–≤.

        –ê—Ä–≥—É–º–µ–Ω—Ç—ã:
            columns_to_drop (list, optional): –°–ø–∏—Å–æ–∫ –∏–º–µ–Ω —Å—Ç–æ–ª–±—Ü–æ–≤, –∫–æ—Ç–æ—Ä—ã–µ –±—É–¥—É—Ç —É–¥–∞–ª–µ–Ω—ã –∏–∑ DataFrame.
                                             –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é None, –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —Å–ø–∏—Å–æ–∫ —Å—Ç–æ–ª–±—Ü–æ–≤ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é.
            min_description_length (int, optional): –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è –¥–ª–∏–Ω–∞ –∫–æ—Ä–æ—Ç–∫–æ–≥–æ –æ–ø–∏—Å–∞–Ω–∏—è –∏–≥—Ä—ã –ø–æ—Å–ª–µ –æ—á–∏—Å—Ç–∫–∏.
                                                    –û–ø–∏—Å–∞–Ω–∏—è –∫–æ—Ä–æ—á–µ —ç—Ç–æ–≥–æ –∑–Ω–∞—á–µ–Ω–∏—è –±—É–¥—É—Ç –æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω—ã. –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é 30.
            max_description_length (int, optional): –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –¥–ª–∏–Ω–∞ –∫–æ—Ä–æ—Ç–∫–æ–≥–æ –æ–ø–∏—Å–∞–Ω–∏—è –∏–≥—Ä—ã –ø–æ—Å–ª–µ –æ—á–∏—Å—Ç–∫–∏.
                                                    –û–ø–∏—Å–∞–Ω–∏—è –¥–ª–∏–Ω–Ω–µ–µ —ç—Ç–æ–≥–æ –∑–Ω–∞—á–µ–Ω–∏—è –±—É–¥—É—Ç –æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω—ã. –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é 240.
            min_tags (int, optional): –ú–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–µ–≥–æ–≤, –∫–æ—Ç–æ—Ä–æ–µ –¥–æ–ª–∂–Ω–∞ —Å–æ–¥–µ—Ä–∂–∞—Ç—å –∏–≥—Ä–∞, —á—Ç–æ–±—ã –æ—Å—Ç–∞—Ç—å—Å—è –≤ –Ω–∞–±–æ—Ä–µ –¥–∞–Ω–Ω—ã—Ö.
                                      –ò–≥—Ä—ã —Å –º–µ–Ω—å—à–∏–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ–º —Ç–µ–≥–æ–≤ –±—É–¥—É—Ç –æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω—ã. –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é 3.
            words_to_remove (list, optional): –°–ø–∏—Å–æ–∫ —Å–ª–æ–≤, –∫–æ—Ç–æ—Ä—ã–µ –±—É–¥—É—Ç —É–¥–∞–ª–µ–Ω—ã –∏–∑ –æ–ø–∏—Å–∞–Ω–∏–π –∏–≥—Ä.
                                             –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –¥–ª—è —É–¥–∞–ª–µ–Ω–∏—è –æ–±—â–∏—Ö –∏ –Ω–µ–∏–Ω—Ñ–æ—Ä–º–∞—Ç–∏–≤–Ω—ã—Ö —Å–ª–æ–≤. –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é ['game', 'world'].

        –í—ã–≤–æ–¥–∏—Ç —Å–æ–æ–±—â–µ–Ω–∏–µ –≤ –∫–æ–Ω—Å–æ–ª—å –æ–± —É—Å–ø–µ—à–Ω–æ–π –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ DataCleaner.
        –ó–∞–≥—Ä—É–∂–∞–µ—Ç –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ —Ä–µ—Å—É—Ä—Å—ã NLTK (stopwords, wordnet) –ø—Ä–∏ –ø–µ—Ä–≤–æ–º –∑–∞–ø—É—Å–∫–µ.
        """
        self.columns_to_drop = columns_to_drop if columns_to_drop else [
            'price', 'dlc_count', 'about_the_game',
            'reviews', 'website', 'support_url',
            'support_email', 'metacritic_score',
            'metacritic_url', 'achievements', 'recommendations',
            'notes', 'full_audio_languages', 'packages',
            'user_score', 'score_rank',
            'screenshots', 'movies',
            'average_playtime_forever', 'average_playtime_2weeks',
            'median_playtime_forever', 'median_playtime_2weeks',
            'peak_ccu'
        ]
        self.min_description_length = min_description_length
        self.max_description_length = max_description_length
        self.min_tags = min_tags
        self.words_to_remove = words_to_remove
        print("‚úÖ DataCleaner –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω.")

        try:
            stopwords.words('english')
        except LookupError:
            nltk.download('stopwords')
        try:
            wordnet_lemmatizer = WordNetLemmatizer()
            wordnet_lemmatizer.lemmatize('cats')
        except LookupError:
            nltk.download('wordnet')
            nltk.download('omw-1.4')

        self.lemmatizer_en = WordNetLemmatizer()
        self.stop_words_en = set(stopwords.words('english'))

        self.morph = pymorphy2.MorphAnalyzer()
        self.stop_words_ru = set(stopwords.words('russian'))


    def _drop_unnecessary_columns(self, df):
        """–£–¥–∞–ª—è–µ—Ç –∑–∞–¥–∞–Ω–Ω—ã–µ —Å—Ç–æ–ª–±—Ü—ã –∏–∑ DataFrame.

        –ò—Å–∫–ª—é—á–∞–µ—Ç –∏–∑ DataFrame —Å—Ç–æ–ª–±—Ü—ã, –ø–µ—Ä–µ—á–∏—Å–ª–µ–Ω–Ω—ã–µ –≤ `self.columns_to_drop`.
        –£–¥–∞–ª–µ–Ω–∏–µ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç—Å—è –Ω–∞ –º–µ—Å—Ç–µ (inplace).

        –ê—Ä–≥—É–º–µ–Ω—Ç—ã:
            df (pandas.DataFrame): DataFrame, –∏–∑ –∫–æ—Ç–æ—Ä–æ–≥–æ –Ω—É–∂–Ω–æ —É–¥–∞–ª–∏—Ç—å —Å—Ç–æ–ª–±—Ü—ã.

        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç:
            pandas.DataFrame: DataFrame —Å —É–¥–∞–ª–µ–Ω–Ω—ã–º–∏ —Å—Ç–æ–ª–±—Ü–∞–º–∏.
        """
        initial_shape = df.shape
        columns_to_drop_exist = [col for col in self.columns_to_drop if col in df.columns]
        df.drop(columns=columns_to_drop_exist, inplace=True, errors='ignore')
        return df

    def _filter_rows(self, df):
        """
        –§–∏–ª—å—Ç—Ä—É–µ—Ç —Å—Ç—Ä–æ–∫–∏ DataFrame –ø–æ –Ω–∞–±–æ—Ä—É —É—Å–ª–æ–≤–∏–π.

        –£–¥–∞–ª—è–µ—Ç —Å—Ç—Ä–æ–∫–∏, –∫–æ—Ç–æ—Ä—ã–µ –Ω–µ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—Ç –∫—Ä–∏—Ç–µ—Ä–∏—è–º –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–≥–æ –∫–∞—á–µ—Å—Ç–≤–∞ –¥–∞–Ω–Ω—ã—Ö,
        —Ç–∞–∫–∏–º –∫–∞–∫ –Ω–∞–ª–∏—á–∏–µ –∫–æ—Ä–æ—Ç–∫–æ–≥–æ –∏ –ø–æ–¥—Ä–æ–±–Ω–æ–≥–æ –æ–ø–∏—Å–∞–Ω–∏—è, –∏–º–µ–Ω–∏, –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è, –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã—Ö —è–∑—ã–∫–æ–≤ –∏ –∫–∞—Ç–µ–≥–æ—Ä–∏–π.

        –ê—Ä–≥—É–º–µ–Ω—Ç—ã:
            df (pandas.DataFrame): DataFrame –¥–ª—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏.

        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç:
            pandas.DataFrame: –û—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–Ω—ã–π DataFrame.
        """
        initial_shape = df.shape

        mask_to_remove = (
            ((df['short_description'].isna()) | (df['short_description'] == '')) |
            ((df['detailed_description'].isna()) | (df['detailed_description'] == '')) |
            (df['name'].str.contains('playtest', case=False, na=False)) |
            ((df['header_image'].isna()) | (df['header_image'] == '')) |
            (df['supported_languages'].astype(str) == '[]') |
            (df['categories'].astype(str) == '[]')
        )
        df_filtered = df[~mask_to_remove].copy()
        return df_filtered

    def _filter_name_chars(self, df):
        """
        –§–∏–ª—å—Ç—Ä—É–µ—Ç DataFrame, –æ—Å—Ç–∞–≤–ª—è—è —Ç–æ–ª—å–∫–æ –∏–≥—Ä—ã —Å –∏–º–µ–Ω–∞–º–∏, —Å–æ–¥–µ—Ä–∂–∞—â–∏–º–∏ –ª–∞—Ç–∏–Ω—Å–∫–∏–µ –±—É–∫–≤—ã, —Ü–∏—Ñ—Ä—ã –∏ –ø—Ä–æ–±–µ–ª—ã.

        –£–¥–∞–ª—è–µ—Ç –∏–≥—Ä—ã, –∏–º–µ–Ω–∞ –∫–æ—Ç–æ—Ä—ã—Ö —Å–æ–¥–µ—Ä–∂–∞—Ç —Å–∏–º–≤–æ–ª—ã, –æ—Ç–ª–∏—á–Ω—ã–µ –æ—Ç –ª–∞—Ç–∏–Ω—Å–∫–∏—Ö –±—É–∫–≤, —Ü–∏—Ñ—Ä –∏ –ø—Ä–æ–±–µ–ª–æ–≤,
        –¥–ª—è –æ–±–µ—Å–ø–µ—á–µ–Ω–∏—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏ –∏ —É–ø—Ä–æ—â–µ–Ω–∏—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∏–º–µ–Ω.

        –ê—Ä–≥—É–º–µ–Ω—Ç—ã:
            df (pandas.DataFrame): DataFrame –¥–ª—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏.

        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç:
            pandas.DataFrame: –û—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–Ω—ã–π DataFrame.
        """
        initial_shape = df.shape

        def clean_name(text):
             if isinstance(text, str):
                 return re.sub(r'[^a-zA-Z0-9\s]', '', text)
             return text

        df['name'] = df['name'].apply(clean_name)

        def is_valid_name(text):
            if isinstance(text, str):
                return bool(re.fullmatch(r'[a-zA-Z0-9\s]+', text))
            return False

        mask_to_remove = ~df['name'].apply(is_valid_name)
        df_filtered = df[~mask_to_remove].copy()
        return df_filtered


    def _convert_release_date(self, df):
        """
        –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç —Å—Ç–æ–ª–±–µ—Ü 'release_date' –≤ —Ñ–æ—Ä–º–∞—Ç datetime.

        –ò—Å–ø–æ–ª—å–∑—É–µ—Ç pandas `to_datetime` –¥–ª—è –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è –¥–∞—Ç –≤—ã–ø—É—Å–∫–∞ –∏–≥—Ä –≤ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç datetime,
        –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—è –æ—à–∏–±–∫–∏ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è –∏ —É—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞—è –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–µ –¥–∞—Ç—ã –≤ NaT (Not a Time).

        –ê—Ä–≥—É–º–µ–Ω—Ç—ã:
            df (pandas.DataFrame): DataFrame, —Å–æ–¥–µ—Ä–∂–∞—â–∏–π —Å—Ç–æ–ª–±–µ—Ü 'release_date'.

        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç:
            pandas.DataFrame: DataFrame —Å –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–Ω—ã–º —Å—Ç–æ–ª–±—Ü–æ–º 'release_date'.
        """
        initial_shape = df.shape
        df['release_date'] = pd.to_datetime(df['release_date'], errors='coerce')
        return df

    def _convert_bool_columns(self, df):
         """
        –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç —Å—Ç–æ–ª–±—Ü—ã 'windows', 'mac', 'linux' –≤ –±—É–ª–µ–≤—ã–π —Ç–∏–ø –¥–∞–Ω–Ω—ã—Ö.

        –ü—Ä–∏–≤–æ–¥–∏—Ç –∑–Ω–∞—á–µ–Ω–∏—è –≤ —Å—Ç–æ–ª–±—Ü–∞—Ö, –æ–±–æ–∑–Ω–∞—á–∞—é—â–∏—Ö –ø–æ–¥–¥–µ—Ä–∂–∫—É –ø–ª–∞—Ç—Ñ–æ—Ä–º, –∫ –±—É–ª–µ–≤–æ–º—É —Ç–∏–ø—É,
        —á—Ç–æ–±—ã —É–ø—Ä–æ—Å—Ç–∏—Ç—å –ª–æ–≥–∏—á–µ—Å–∫–∏–µ –æ–ø–µ—Ä–∞—Ü–∏–∏ –∏ —É–º–µ–Ω—å—à–∏—Ç—å –æ–±—ä–µ–º –ø–∞–º—è—Ç–∏, –∏—Å–ø–æ–ª—å–∑—É–µ–º—ã–π –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è —ç—Ç–∏—Ö –¥–∞–Ω–Ω—ã—Ö.

        –ê—Ä–≥—É–º–µ–Ω—Ç—ã:
            df (pandas.DataFrame): DataFrame, —Å–æ–¥–µ—Ä–∂–∞—â–∏–π —Å—Ç–æ–ª–±—Ü—ã –¥–ª—è –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è ('windows', 'mac', 'linux').

        Returns:
            pandas.DataFrame: DataFrame —Å –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–Ω—ã–º–∏ –±—É–ª–µ–≤—ã–º–∏ —Å—Ç–æ–ª–±—Ü–∞–º–∏.
        """
         initial_shape = df.shape
         bool_mapping = {'true': True, 'false': False}
         for col in ['windows', 'mac', 'linux']:
              if col in df.columns:
                df[col] = df[col].astype(str).str.lower().replace({'nan': None})
                df[col] = df[col].map(bool_mapping).fillna(False).astype(bool)
         return df

    def _extract_owners(self, df):
         """
        –ò–∑–≤–ª–µ–∫–∞–µ—Ç —á–∏—Å–ª–µ–Ω–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ –∏–∑ —Å—Ç–æ–ª–±—Ü–∞ 'estimated_owners'.

        –ü–∞—Ä—Å–∏—Ç —Å—Ç–æ–ª–±–µ—Ü 'estimated_owners', –∫–æ—Ç–æ—Ä—ã–π —Å–æ–¥–µ—Ä–∂–∏—Ç –¥–∏–∞–ø–∞–∑–æ–Ω—ã –æ—Ü–µ–Ω–æ—á–Ω–æ–≥–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –≤–ª–∞–¥–µ–ª—å—Ü–µ–≤,
        –∏ –∏–∑–≤–ª–µ–∫–∞–µ—Ç –Ω–∏–∂–Ω—é—é –≥—Ä–∞–Ω–∏—Ü—É –¥–∏–∞–ø–∞–∑–æ–Ω–∞ –∫–∞–∫ —á–∏—Å–ª–µ–Ω–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ, –ø—Ä–∏–≤–æ–¥—è –µ–≥–æ –∫ —Ü–µ–ª–æ–º—É —Ç–∏–ø—É.

        –ê—Ä–≥—É–º–µ–Ω—Ç—ã:
            df (pandas.DataFrame): DataFrame, —Å–æ–¥–µ—Ä–∂–∞—â–∏–π —Å—Ç–æ–ª–±–µ—Ü 'estimated_owners'.

        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç:
            pandas.DataFrame: DataFrame —Å –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–Ω—ã–º —Å—Ç–æ–ª–±—Ü–æ–º 'estimated_owners', —Å–æ–¥–µ—Ä–∂–∞—â–∏–º —Ü–µ–ª–æ—á–∏—Å–ª–µ–Ω–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è.
        """
         initial_shape = df.shape
         def extract_first_number(owner_range):
            if isinstance(owner_range, str):
                parts = owner_range.split(' ', 1)
                first_part = parts[0].replace(',', '')
                try:
                   return int(first_part)
                except ValueError:
                    return None
            return None

         df['estimated_owners'] = df['estimated_owners'].apply(extract_first_number)
         return df

    def _combine_tags(self, df):
         """
        –û–±—ä–µ–¥–∏–Ω—è–µ—Ç —Ç–µ–≥–∏ –∏–∑ —Å—Ç–æ–ª–±—Ü–æ–≤ 'categories', 'genres' –∏ 'tags' –≤ –æ–¥–∏–Ω —Å—Ç–æ–ª–±–µ—Ü 'all_tags'.

        –°–æ–±–∏—Ä–∞–µ—Ç –≤—Å–µ —Ç–µ–≥–∏, –æ—Ç–Ω–æ—Å—è—â–∏–µ—Å—è –∫ –∏–≥—Ä–µ, –∏–∑ —Ä–∞–∑–Ω—ã—Ö —Å—Ç–æ–ª–±—Ü–æ–≤ –∏ —Å–æ–∑–¥–∞–µ—Ç –µ–¥–∏–Ω—ã–π —Å–ø–∏—Å–æ–∫ —Ç–µ–≥–æ–≤ –¥–ª—è –∫–∞–∂–¥–æ–π –∏–≥—Ä—ã,
        —á—Ç–æ–±—ã —É–ø—Ä–æ—Å—Ç–∏—Ç—å –¥–∞–ª—å–Ω–µ–π—à–∏–π –∞–Ω–∞–ª–∏–∑ –∏ –≤–µ–∫—Ç–æ—Ä–∏–∑–∞—Ü–∏—é —Ç–µ–≥–æ–≤.

        –ê—Ä–≥—É–º–µ–Ω—Ç—ã:
            df (pandas.DataFrame): DataFrame, —Å–æ–¥–µ—Ä–∂–∞—â–∏–π —Å—Ç–æ–ª–±—Ü—ã 'categories', 'genres' –∏ 'tags'.

        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç:
            pandas.DataFrame: DataFrame —Å –¥–æ–±–∞–≤–ª–µ–Ω–Ω—ã–º —Å—Ç–æ–ª–±—Ü–æ–º 'all_tags', —Å–æ–¥–µ—Ä–∂–∞—â–∏–º —Å–ø–∏—Å–∫–∏ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–Ω—ã—Ö —Ç–µ–≥–æ–≤.
        """
         initial_shape = df.shape
         def combine_tags(row):
            all_tags_list = []

            if isinstance(row['categories'], list):
                all_tags_list.extend(row['categories'])

            if isinstance(row['genres'], list):
                all_tags_list.extend(row['genres'])

            if 'tags' in row and isinstance(row['tags'], dict):
                all_tags_list.extend(row['tags'].keys())

            return list(set(all_tags_list))

         df['all_tags'] = df.apply(combine_tags, axis=1)
         return df

    def _replace_empty_values(self, df):
        """
        –ó–∞–º–µ–Ω—è–µ—Ç –ø—É—Å—Ç—ã–µ —Å–ø–∏—Å–∫–∏ –∏ —Å—Ç—Ä–æ–∫–∏ –≤ —Å—Ç–æ–ª–±—Ü–∞—Ö 'developers' –∏ 'publishers' –Ω–∞ None.

        –ù–æ—Ä–º–∞–ª–∏–∑—É–µ—Ç –∑–Ω–∞—á–µ–Ω–∏—è –≤ —Å—Ç–æ–ª–±—Ü–∞—Ö 'developers' –∏ 'publishers', –∑–∞–º–µ–Ω—è—è –ø—É—Å—Ç—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è –Ω–∞ None,
        —á—Ç–æ–±—ã –æ–±–µ—Å–ø–µ—á–∏—Ç—å –µ–¥–∏–Ω–æ–æ–±—Ä–∞–∑–∏–µ –∏ —É–ø—Ä–æ—Å—Ç–∏—Ç—å –æ–±—Ä–∞–±–æ—Ç–∫—É –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—â–∏—Ö –¥–∞–Ω–Ω—ã—Ö.

        –ê—Ä–≥—É–º–µ–Ω—Ç—ã:
            df (pandas.DataFrame): DataFrame, —Å–æ–¥–µ—Ä–∂–∞—â–∏–π —Å—Ç–æ–ª–±—Ü—ã 'developers' –∏ 'publishers'.

        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç:
            pandas.DataFrame: DataFrame —Å –∑–∞–º–µ–Ω–µ–Ω–Ω—ã–º–∏ –ø—É—Å—Ç—ã–º–∏ –∑–Ω–∞—á–µ–Ω–∏—è–º–∏ –≤ —Å—Ç–æ–ª–±—Ü–∞—Ö 'developers' –∏ 'publishers'.
        """
        initial_shape = df.shape
        def replace_empty_with_none(series):
            def replace_item(item):
                if item == [] or item == [''] or item == [""] or item == "":
                    return None
                return item

            return series.apply(replace_item)

        if 'developers' in df.columns:
            df['developers'] = replace_empty_with_none(df['developers'])
        if 'publishers' in df.columns:
            df['publishers'] = replace_empty_with_none(df['publishers'])
        return df

    def _filter_by_language(self, df):
        """
        –§–∏–ª—å—Ç—Ä—É–µ—Ç DataFrame, –æ—Å—Ç–∞–≤–ª—è—è —Ç–æ–ª—å–∫–æ –æ–ø–∏—Å–∞–Ω–∏—è –Ω–∞ –∞–Ω–≥–ª–∏–π—Å–∫–æ–º –∏–ª–∏ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–∞—Ö.

        –ò—Å–ø–æ–ª—å–∑—É–µ—Ç `langdetect` –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —è–∑—ã–∫–∞ –æ–ø–∏—Å–∞–Ω–∏–π –∏–≥—Ä –∏ –æ—Å—Ç–∞–≤–ª—è–µ—Ç —Ç–æ–ª—å–∫–æ —Ç–µ —Å—Ç—Ä–æ–∫–∏,
        –≥–¥–µ –∏ –∫–æ—Ä–æ—Ç–∫–æ–µ, –∏ –ø–æ–¥—Ä–æ–±–Ω–æ–µ –æ–ø–∏—Å–∞–Ω–∏—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω—ã –∫–∞–∫ –∞–Ω–≥–ª–∏–π—Å–∫–∏–µ ('en') –∏–ª–∏ —Ä—É—Å—Å–∫–∏–µ ('ru').

        –ê—Ä–≥—É–º–µ–Ω—Ç—ã:
            df (pandas.DataFrame): DataFrame, —Å–æ–¥–µ—Ä–∂–∞—â–∏–π —Å—Ç–æ–ª–±—Ü—ã 'detailed_description' –∏ 'short_description'.

        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç:
            pandas.DataFrame: –û—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–Ω—ã–π DataFrame, —Å–æ–¥–µ—Ä–∂–∞—â–∏–π —Ç–æ–ª—å–∫–æ –æ–ø–∏—Å–∞–Ω–∏—è –Ω–∞ –∞–Ω–≥–ª–∏–π—Å–∫–æ–º –∏–ª–∏ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–∞—Ö.
        """
        initial_shape = df.shape

        def is_english_or_russian(text):
           if not isinstance(text, str):
                return False
           try:
                lang = detect(text)
                return lang == 'en' or lang == 'ru'
           except LangDetectException:
               return False

        df['detailed_is_en_ru'] = df['detailed_description'].apply(is_english_or_russian)
        df['short_is_en_ru'] = df['short_description'].apply(is_english_or_russian)

        df_filtered = df[df['detailed_is_en_ru'] & df['short_is_en_ru']].copy()
        df_filtered = df_filtered.drop(columns=['detailed_is_en_ru', 'short_is_en_ru'], errors='ignore')
        return df_filtered

    def _clean_and_lemmatize_descriptions(self, df):
        """
        –û—á–∏—â–∞–µ—Ç –∏ –ª–µ–º–º–∞—Ç–∏–∑–∏—Ä—É–µ—Ç —Ç–µ–∫—Å—Ç–æ–≤—ã–µ –æ–ø–∏—Å–∞–Ω–∏—è –∏–≥—Ä.

        –ü—Ä–∏–º–µ–Ω—è–µ—Ç –æ—á–∏—Å—Ç–∫—É —Ç–µ–∫—Å—Ç–∞, –≤–∫–ª—é—á–∞—è –ø—Ä–∏–≤–µ–¥–µ–Ω–∏–µ –∫ –Ω–∏–∂–Ω–µ–º—É —Ä–µ–≥–∏—Å—Ç—Ä—É, —É–¥–∞–ª–µ–Ω–∏–µ –∑–Ω–∞–∫–æ–≤ –ø—É–Ω–∫—Ç—É–∞—Ü–∏–∏ –∏ —Ü–∏—Ñ—Ä,
        –∞ —Ç–∞–∫–∂–µ –ª–µ–º–º–∞—Ç–∏–∑–∞—Ü–∏—é —Å–ª–æ–≤ –¥–ª—è –∞–Ω–≥–ª–∏–π—Å–∫–æ–≥–æ –∏ —Ä—É—Å—Å–∫–æ–≥–æ —è–∑—ã–∫–æ–≤ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º NLTK –∏ pymorphy2.

        –ê—Ä–≥—É–º–µ–Ω—Ç—ã:
            df (pandas.DataFrame): DataFrame, —Å–æ–¥–µ—Ä–∂–∞—â–∏–π —Å—Ç–æ–ª–±—Ü—ã 'detailed_description' –∏ 'short_description'.

        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç:
            pandas.DataFrame: DataFrame —Å –¥–æ–±–∞–≤–ª–µ–Ω–Ω—ã–º–∏ —Å—Ç–æ–ª–±—Ü–∞–º–∏ '_clean' –¥–ª—è –æ—á–∏—â–µ–Ω–Ω—ã—Ö –æ–ø–∏—Å–∞–Ω–∏–π ('detailed_description_clean', 'short_description_clean').
        """
        initial_shape = df.shape

        def clean_and_lemmatize(text, lang='en'):
            if not isinstance(text, str):
                return ""

            text = text.lower()
            text = re.sub(r'[^\w\s]', '', text)
            text = re.sub(r'\d+', '', text)

            words = text.split()

            if lang == 'ru':
                lemmatized_words = [self.morph.parse(word)[0].normal_form for word in words if word not in self.stop_words_ru]
            else:
                lemmatized_words = [self.lemmatizer_en.lemmatize(word) for word in words if word not in self.stop_words_en]

            return " ".join(lemmatized_words)

        df['detailed_description_clean'] = df['detailed_description'].apply(lambda x: clean_and_lemmatize(x))
        df['short_description_clean'] = df['short_description'].apply(lambda x: clean_and_lemmatize(x))
        return df

    def _remove_specific_words_from_descriptions(self, df):
        """
        –£–¥–∞–ª—è–µ—Ç –∑–∞–¥–∞–Ω–Ω—ã–µ —Å–ª–æ–≤–∞ –∏–∑ –æ—á–∏—â–µ–Ω–Ω—ã—Ö –æ–ø–∏—Å–∞–Ω–∏–π –∏–≥—Ä.

        –ò—Å–∫–ª—é—á–∞–µ—Ç —Å–ª–æ–≤–∞, –ø–µ—Ä–µ—á–∏—Å–ª–µ–Ω–Ω—ã–µ –≤ `self.words_to_remove`, –∏–∑ –æ—á–∏—â–µ–Ω–Ω—ã—Ö –∫–æ—Ä–æ—Ç–∫–∏—Ö –∏ –ø–æ–¥—Ä–æ–±–Ω—ã—Ö –æ–ø–∏—Å–∞–Ω–∏–π –∏–≥—Ä,
        —á—Ç–æ–±—ã —É–±—Ä–∞—Ç—å –æ–±—â–∏–µ –∏ –Ω–µ—Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ —Å–ª–æ–≤–∞, —Å–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã–µ –¥–ª—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –∏–≥—Ä.

        –ê—Ä–≥—É–º–µ–Ω—Ç—ã:
            df (pandas.DataFrame): DataFrame, —Å–æ–¥–µ—Ä–∂–∞—â–∏–π —Å—Ç–æ–ª–±—Ü—ã 'short_description_clean' –∏ 'detailed_description_clean'.

        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç:
            pandas.DataFrame: DataFrame —Å —É–¥–∞–ª–µ–Ω–Ω—ã–º–∏ —Å–ø–µ—Ü–∏—Ñ–∏—á–µ—Å–∫–∏–º–∏ —Å–ª–æ–≤–∞–º–∏ –∏–∑ –æ—á–∏—â–µ–Ω–Ω—ã—Ö –æ–ø–∏—Å–∞–Ω–∏–π.
        """
        initial_shape = df.shape
        def remove_words(text):
            if isinstance(text, str):
                words = text.split()
                filtered_words = [word for word in words if word not in self.words_to_remove]
                return ' '.join(filtered_words)
            return text

        df['short_description_clean'] = df['short_description_clean'].apply(remove_words)
        df['detailed_description_clean'] = df['detailed_description_clean'].apply(remove_words)
        return df

    def _filter_description_length(self, df):
        """
        –§–∏–ª—å—Ç—Ä—É–µ—Ç DataFrame –ø–æ –¥–ª–∏–Ω–µ –æ—á–∏—â–µ–Ω–Ω—ã—Ö –∫–æ—Ä–æ—Ç–∫–∏—Ö –æ–ø–∏—Å–∞–Ω–∏–π.

        –£–¥–∞–ª—è–µ—Ç —Å—Ç—Ä–æ–∫–∏, –≥–¥–µ –¥–ª–∏–Ω–∞ –æ—á–∏—â–µ–Ω–Ω–æ–≥–æ –∫–æ—Ä–æ—Ç–∫–æ–≥–æ –æ–ø–∏—Å–∞–Ω–∏—è –Ω–µ –ø–æ–ø–∞–¥–∞–µ—Ç –≤ –∑–∞–¥–∞–Ω–Ω—ã–π –¥–∏–∞–ø–∞–∑–æ–Ω
        (`self.min_description_length` –∏ `self.max_description_length`), —á—Ç–æ–±—ã –æ–±–µ—Å–ø–µ—á–∏—Ç—å –º–∏–Ω–∏–º–∞–ª—å–Ω—É—é –∏ –º–∞–∫—Å–∏–º–∞–ª—å–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ç–∏–≤–Ω–æ—Å—Ç—å –æ–ø–∏—Å–∞–Ω–∏–π.

        –ê—Ä–≥—É–º–µ–Ω—Ç—ã:
            df (pandas.DataFrame): DataFrame, —Å–æ–¥–µ—Ä–∂–∞—â–∏–π —Å—Ç–æ–ª–±–µ—Ü 'short_description_clean'.

        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç:
            pandas.DataFrame: –û—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–Ω—ã–π DataFrame, —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–π –∑–∞–¥–∞–Ω–Ω—ã–º –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è–º –ø–æ –¥–ª–∏–Ω–µ –æ–ø–∏—Å–∞–Ω–∏–π.
        """
        initial_shape = df.shape
        if isinstance(data, str):
            df_filtered = df[(df['short_description_clean'].str.len() >= self.min_description_length) & (df['short_description_clean'].str.len() <= self.max_description_length)].copy()
        else:
            df_filtered = df.copy()
        return df_filtered

    def _clean_and_lowercase_tags(self, df):
        """
        –û—á–∏—â–∞–µ—Ç –∏ –ø—Ä–∏–≤–æ–¥–∏—Ç –∫ –Ω–∏–∂–Ω–µ–º—É —Ä–µ–≥–∏—Å—Ç—Ä—É —Ç–µ–≥–∏ –≤ —Å—Ç–æ–ª–±—Ü–µ 'all_tags'.

        –£–¥–∞–ª—è–µ—Ç –∏–∑ —Ç–µ–≥–æ–≤ —Å–∏–º–≤–æ–ª—ã, –Ω–µ —è–≤–ª—è—é—â–∏–µ—Å—è –±—É–∫–≤–∞–º–∏ –∏–ª–∏ —Ü–∏—Ñ—Ä–∞–º–∏, –ø—Ä–∏–≤–æ–¥–∏—Ç –≤—Å–µ —Ç–µ–≥–∏ –∫ –Ω–∏–∂–Ω–µ–º—É —Ä–µ–≥–∏—Å—Ç—Ä—É
        –∏ —É–¥–∞–ª—è–µ—Ç –ª–∏—à–Ω–∏–µ –ø—Ä–æ–±–µ–ª—ã, –æ–±–µ—Å–ø–µ—á–∏–≤–∞—è —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π –∏ –æ—á–∏—â–µ–Ω–Ω—ã–π –≤–∏–¥ —Ç–µ–≥–æ–≤.

        –ê—Ä–≥—É–º–µ–Ω—Ç—ã:
            df (pandas.DataFrame): DataFrame, —Å–æ–¥–µ—Ä–∂–∞—â–∏–π —Å—Ç–æ–ª–±–µ—Ü 'all_tags'.

        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç:
            pandas.DataFrame: DataFrame —Å –æ—á–∏—â–µ–Ω–Ω—ã–º–∏ –∏ –ø—Ä–∏–≤–µ–¥–µ–Ω–Ω—ã–º–∏ –∫ –Ω–∏–∂–Ω–µ–º—É —Ä–µ–≥–∏—Å—Ç—Ä—É —Ç–µ–≥–∞–º–∏.
        """
        initial_shape = df.shape
        def clean_tags(tags):
            if isinstance(tags, list):
                cleaned_tags = [re.sub(r'[^a-zA-Z0-9\s]', '', tag).lower().strip() for tag in tags]
                return cleaned_tags
            return tags

        df['all_tags'] = df['all_tags'].apply(clean_tags)
        return df

    def _filter_tags_count(self, df):
        """
        –§–∏–ª—å—Ç—Ä—É–µ—Ç DataFrame –ø–æ –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–º—É –∫–æ–ª–∏—á–µ—Å—Ç–≤—É —Ç–µ–≥–æ–≤ –≤ —Å—Ç–æ–ª–±—Ü–µ 'all_tags'.

        –£–¥–∞–ª—è–µ—Ç —Å—Ç—Ä–æ–∫–∏, –≥–¥–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–µ–≥–æ–≤ –≤ —Å–ø–∏—Å–∫–µ 'all_tags' –º–µ–Ω—å—à–µ, —á–µ–º –∑–∞–¥–∞–Ω–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ `self.min_tags`,
        —á—Ç–æ–±—ã –æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞—Ç—å –∏–≥—Ä—ã —Å –Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω—ã–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ–º —Ç–µ–≥–æ–≤ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞.

        –ê—Ä–≥—É–º–µ–Ω—Ç—ã:
            df (pandas.DataFrame): DataFrame, —Å–æ–¥–µ—Ä–∂–∞—â–∏–π —Å—Ç–æ–ª–±–µ—Ü 'all_tags'.

        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç:
            pandas.DataFrame: –û—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–Ω—ã–π DataFrame, —Å–æ–¥–µ—Ä–∂–∞—â–∏–π —Ç–æ–ª—å–∫–æ –∏–≥—Ä—ã —Å –¥–æ—Å—Ç–∞—Ç–æ—á–Ω—ã–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ–º —Ç–µ–≥–æ–≤.
        """
        initial_shape = df.shape
        df_filtered = df[df['all_tags'].apply(lambda x: isinstance(x, list) and len(x) >= self.min_tags)].copy()
        return df_filtered

    def clean_data(self, data):
         """
        –ö–æ–æ—Ä–¥–∏–Ω–∏—Ä—É–µ—Ç –ø—Ä–æ—Ü–µ—Å—Å –æ—á–∏—Å—Ç–∫–∏ –¥–∞–Ω–Ω—ã—Ö DataFrame.

        –í—ã–∑—ã–≤–∞–µ—Ç –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ –≤—Å–µ –º–µ—Ç–æ–¥—ã –æ—á–∏—Å—Ç–∫–∏ –¥–∞–Ω–Ω—ã—Ö, –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω—ã–µ –≤ –∫–ª–∞—Å—Å–µ,
        –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ DataFrame –∏ –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∏ –¥–∞–Ω–Ω—ã—Ö –∫ –¥–∞–ª—å–Ω–µ–π—à–µ–º—É –∞–Ω–∞–ª–∏–∑—É –∏–ª–∏ –º–æ–¥–µ–ª–∏—Ä–æ–≤–∞–Ω–∏—é.
        –ú–µ—Ç–æ–¥ –º–æ–∂–µ—Ç –ø—Ä–∏–Ω–∏–º–∞—Ç—å –∫–∞–∫ DataFrame, —Ç–∞–∫ –∏ –ø—É—Ç—å –∫ —Ñ–∞–π–ª—É —Å –¥–∞–Ω–Ω—ã–º–∏.

        –ê—Ä–≥—É–º–µ–Ω—Ç—ã:
            data (pandas.DataFrame –∏–ª–∏ str): DataFrame –¥–ª—è –æ—á–∏—Å—Ç–∫–∏ –∏–ª–∏ –ø—É—Ç—å –∫ —Ñ–∞–π–ª—É (JSON, CSV), –∫–æ—Ç–æ—Ä—ã–π –Ω—É–∂–Ω–æ –∑–∞–≥—Ä—É–∑–∏—Ç—å –∏ –æ—á–∏—Å—Ç–∏—Ç—å.

        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç:
            pandas.DataFrame: –û—á–∏—â–µ–Ω–Ω—ã–π DataFrame.

        –í—ã–∑—ã–≤–∞–µ—Ç:
            ValueError: –ï—Å–ª–∏ –≤—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –Ω–µ —è–≤–ª—è—é—Ç—Å—è DataFrame –∏ –Ω–µ —Å—Ç—Ä–æ–∫–æ–π (–ø—É—Ç–µ–º –∫ —Ñ–∞–π–ª—É).

        –í—ã–≤–æ–¥–∏—Ç –≤ –∫–æ–Ω—Å–æ–ª—å —Å–æ–æ–±—â–µ–Ω–∏—è –æ –Ω–∞—á–∞–ª–µ –∏ –∑–∞–≤–µ—Ä—à–µ–Ω–∏–∏ –ø—Ä–æ—Ü–µ—Å—Å–∞ –æ—á–∏—Å—Ç–∫–∏, –∞ —Ç–∞–∫–∂–µ –Ω–∞—á–∞–ª—å–Ω—É—é –∏ –∫–æ–Ω–µ—á–Ω—É—é —Ñ–æ—Ä–º—É DataFrame.
        """
         print("üßπ –ù–∞—á–∏–Ω–∞–µ—Ç—Å—è –ø—Ä–æ—Ü–µ—Å—Å –æ—á–∏—Å—Ç–∫–∏ –¥–∞–Ω–Ω—ã—Ö...")
         if isinstance(data, str):
              file_handler = FileHandler()
              df = file_handler.load_data(data)
              apply_description_length_filter = True
         elif isinstance(data, pd.DataFrame):
             df = data.copy()
             apply_description_length_filter = False
         else:
             raise ValueError("‚ùå –í—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å pandas DataFrame –∏–ª–∏ –ø—É—Ç–µ–º –∫ —Ñ–∞–π–ª—É.")

         initial_shape = df.shape
         print(f"üìä –ò—Å—Ö–æ–¥–Ω–∞—è —Ñ–æ—Ä–º–∞ DataFrame –ø–µ—Ä–µ–¥ –æ—á–∏—Å—Ç–∫–æ–π: {initial_shape}")

         df = self._filter_rows(df)
         df = self._combine_tags(df)
         df = self._drop_unnecessary_columns(df)
         df = self._filter_name_chars(df)
         df = self._convert_release_date(df)
         df = self._convert_bool_columns(df)
         df = self._extract_owners(df)
         df = self._replace_empty_values(df)
         df = self._filter_by_language(df)
         df = self._clean_and_lemmatize_descriptions(df)
         df = self._remove_specific_words_from_descriptions(df)
         if apply_description_length_filter:
            df = self._filter_description_length(df)
         df = self._clean_and_lowercase_tags(df)
         df = self._filter_tags_count(df)

         print(f"‚úÖ –ü—Ä–æ—Ü–µ—Å—Å –æ—á–∏—Å—Ç–∫–∏ –¥–∞–Ω–Ω—ã—Ö –∑–∞–≤–µ—Ä—à–µ–Ω. –ò—Ç–æ–≥–æ–≤–∞—è —Ñ–æ—Ä–º–∞: {df.shape}")
         return df


if __name__ == '__main__':
    project_root = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
    raw_data_path = os.path.join(project_root, 'data', 'raw', 'steam_games.json')
    processed_data_path = os.path.join(project_root, 'data', 'processed', 'steam_games_data_cleaned_test.json')

    data = {
        'name': [
            'Game 1', 'Game 2', 'Game 3', 'Game 4', 'Game 5', 'Game 6', 'Game 7', 'Game 8', 'Game 9', 'Game 10',
            'Game 11', 'Game 12', 'Game 13', 'Game 14', 'Game 15', 'Game 16', 'Game 17', 'Game 18', 'Game 19', 'Game 20',
            '–¢–µ—Å—Ç–æ–≤–∞—è –∏–≥—Ä–∞ –Ω–∞ —Ä—É—Å—Å–∫–æ–º', '12345', 'Test Playtest Game', 'Test game with numbers 123', 'Another Playtest Game'
        ],
        'short_description': [
            'This is a short description for game one, it is longer than before, testing here',
            'Another short description, this one is also quite long for game two and more test',
            'A short but meaningful description for game three, just a bit long with a bit extra',
            'Short description number four, is also around 30 characters in length, testing here',
            'Description for game five, this is supposed to be a bit longer than usual for this test',
            'Game six has a description that is long enough for our needs, test here, some more words',
            'Another very short description for game seven, should be long enough here, more here',
            'Description for game eight, lets make this at least thirty char long now for the test',
            'Game nine has a description, should be at least thirty characters long test for fun',
            'A short description for game ten, test is still around thirty in length, more here',
            'Game eleven with description, this one should be around thirty char long, test here',
            'Description for game twelve, making this more than thirty char in length, more text',
            'A short one for game thirteen, trying to make this more than 30 char long, more test',
            'Game fourteen short, lets make sure that this one is more than 30 char long with test',
            'Description for game fifteen, testing with more than 30 characters here now for tests',
            'A short description for game sixteen, this is more than 30 characters long now tests',
            'Game seventeen short description, let us make sure is more than 30 char long more tests',
            'Description for game eighteen, making this more than 30 char in length here and test',
            'Another short description nineteen, testing for more than 30 chars now for extra text',
            'A short description for game twenty, this is a long 30 character test for fun here',
            '–ö–æ—Ä–æ—Ç–∫–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ —Ç–µ—Å—Ç–æ–≤–æ–π –∏–≥—Ä—ã', 'short 21', 'Short description of test playtest', 'short description 22 for test', 'Another short description for game'
        ],
        'detailed_description': [
            'This is a detailed description for game one, it is longer than before and has more info here',
            'Another detailed description for game two, this one is also quite long with more content now',
            'A detailed but meaningful description for game three, just a bit long and has details here',
            'Detailed description number four, is also around 30 characters in length and a bit more info',
            'Description for game five, this is supposed to be a bit longer than usual, testing now details',
            'Game six has a description that is long enough for our needs, test here, should be more info',
            'Another very short description for game seven, should be long enough here, with extra details',
            'Description for game eight, lets make this at least thirty char long now and more content test',
            'Game nine has a description, should be at least thirty characters long test now here and more',
            'A short description for game ten, test is still around thirty in length and some extras info here',
            'Game eleven with description, this one should be around thirty char long, test extras here more',
            'Description for game twelve, making this more than thirty char in length, test details now here',
            'A short one for game thirteen, trying to make this more than 30 char long and more here and info',
            'Game fourteen short, lets make sure that this one is more than 30 char long and details for game',
            'Description for game fifteen, testing with more than 30 characters here now with detail info here',
            'A short description for game sixteen, this is more than 30 characters long now details for game',
            'Game seventeen short description, let us make sure is more than 30 char long more now with info',
            'Description for game eighteen, making this more than 30 char in length here and extras here for game',
            'Another short description nineteen, testing for more than 30 chars now with more info here for game',
            'A short description for game twenty, this is a long 30 character test with more details for game',
            '–î–µ—Ç–∞–ª—å–Ω–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ —Ç–µ—Å—Ç–æ–≤–æ–π –∏–≥—Ä—ã', 'detailed 21', 'Detailed description of test playtest game', 'detailed description with number 123 game test', 'Another detailed description of test game'
        ],
        'header_image': [
            'image1', 'image2', 'image3', 'image4', 'image5', 'image6', 'image7', 'image8', 'image9', 'image10',
            'image11', 'image12', 'image13', 'image14', 'image15', 'image16', 'image17', 'image18', 'image19', 'image20',
            'image21', 'image22','image23', 'image24', 'image25'
        ],
        'supported_languages': [
            ['en'], ['en', 'ru'], ['ru'], ['en', 'fr'], ['de'], ['en', 'es'], ['pt'], ['it'], ['ja'], ['ko'],
            ['zh'], ['en', 'de'], ['fr', 'es'], ['pt', 'it'], ['ja', 'ko'], ['en'], ['ru'], ['en', 'fr'], ['de'], ['en', 'es'],
            ['zh'],['en'], ['en', 'ru'],['ru'],['en']
        ],
        'categories': [
            ['Action', 'Adventure', 'Indie'], ['Adventure', 'Indie', 'RPG'], ['Strategy', 'Simulation', 'Sports'], ['RPG', 'Racing', 'Puzzle'], ['Simulation', 'Casual', 'MMO'],
            ['Action', 'Indie', 'Puzzle'], ['Adventure', 'Strategy', 'Racing'], ['Strategy', 'RPG', 'Casual'], ['Simulation', 'Sports', 'MMO'], ['Racing', 'Puzzle', 'Action'],
            ['Action', 'Indie', 'Adventure'], ['Adventure', 'Strategy', 'RPG'], ['Strategy', 'Simulation', 'Sports'], ['Simulation', 'Sports', 'MMO'], ['Racing', 'Puzzle', 'Casual'],
            ['MMO', 'Puzzle', 'Action'], ['Action', 'RPG', 'Simulation'], ['Adventure', 'Sports', 'Racing'], ['Strategy', 'Puzzle', 'Casual'], ['RPG', 'MMO', 'Action'],
            ['Action', 'Adventure'], ['Strategy', 'RPG'],['Action', 'Indie'],['Strategy','Sports'],['Action','Simulation']
        ],
        'tags': [
            {'Action': '1', 'Adventure': '2', 'Indie': '3'}, {'Indie': '2', 'Adventure': '3', 'RPG': '4'}, {'Strategy': '4', 'Simulation': '5', 'Sports': '6'},
            {'RPG': '5', 'Racing': '6', 'Puzzle': '7'}, {'Simulation': '6', 'Casual': '7', 'MMO': '8'}, {'Action': '7', 'Indie': '8', 'Puzzle': '9'},
            {'Adventure': '8', 'Strategy': '9', 'Racing': '10'}, {'Strategy': '9', 'RPG': '10', 'Casual': '11'}, {'Simulation': '10', 'Sports': '11', 'MMO': '12'},
            {'Racing': '11', 'Puzzle': '12', 'Action': '13'}, {'Action': '12', 'Indie': '13', 'Adventure': '14'}, {'Adventure': '13', 'Strategy': '14', 'RPG': '15'},
            {'Strategy': '14', 'Simulation': '15', 'Sports': '16'}, {'Simulation': '15', 'Sports': '16', 'MMO': '17'}, {'Racing': '16', 'Puzzle': '17', 'Casual': '18'},
            {'MMO': '17', 'Puzzle': '18', 'Action': '19'}, {'Action': '18', 'RPG': '19', 'Simulation': '20'}, {'Adventure': '19', 'Sports': '20', 'Racing': '21'},
            {'Strategy': '20', 'Puzzle': '21', 'Casual': '22'}, {'RPG': '21', 'MMO': '22', 'Action': '23'},
            {'Action': '1', 'Adventure': '2'},{'Strategy': '4', 'RPG': '5'},{'Action': '1', 'Indie': '2'},{'Strategy': '4', 'Sports': '5'},{'Action': '1', 'Simulation': '2'}
        ],
        'genres': [
            ['Action', 'Adventure', 'Indie'], ['Adventure', 'Indie', 'RPG'], ['Strategy', 'Simulation', 'Sports'], ['RPG', 'Racing', 'Puzzle'], ['Simulation', 'Casual', 'MMO'],
            ['Action', 'Indie', 'Puzzle'], ['Adventure', 'Strategy', 'Racing'], ['Strategy', 'RPG', 'Casual'], ['Simulation', 'Sports', 'MMO'], ['Racing', 'Puzzle', 'Action'],
            ['Action', 'Indie', 'Adventure'], ['Adventure', 'Strategy', 'RPG'], ['Strategy', 'Simulation', 'Sports'], ['Simulation', 'Sports', 'MMO'], ['Racing', 'Puzzle', 'Casual'],
            ['MMO', 'Puzzle', 'Action'], ['Action', 'RPG', 'Simulation'], ['Adventure', 'Sports', 'Racing'], ['Strategy', 'Puzzle', 'Casual'], ['RPG', 'MMO', 'Action'],
            ['Action', 'Adventure'], ['Strategy', 'RPG'],['Action', 'Indie'],['Strategy','Sports'],['Action','Simulation']
        ],
        'release_date': [
            '2023-01-01', '2023-02-01', '2023-03-01', '2023-04-01', '2023-05-01', '2023-06-01', '2023-07-01', '2023-08-01', '2023-09-01', '2023-10-01',
            '2023-11-01', '2023-12-01', '2024-01-01', '2024-02-01', '2024-03-01', '2024-04-01', '2024-05-01', '2024-06-01', '2024-07-01', '2024-08-01',
            '2024-01-01', '2024-01-01','2024-01-01', '2024-01-01', '2024-01-01'
        ],
        'windows': [
            'true', 'true', 'false', 'true', 'false', 'true', 'false', 'true', 'false', 'true',
            'false', 'true', 'false', 'true', 'false', 'true', 'false', 'true', 'false', 'true',
            'true', 'false', 'true', 'true', 'false'
        ],
        'mac': [
            'true', 'false', 'false', 'true', 'false', 'true', 'false', 'true', 'false', 'true',
            'false', 'true', 'false', 'true', 'false', 'true', 'false', 'true', 'false', 'true',
            'true', 'false', 'false', 'false', 'true'
        ],
        'linux': [
            'false', 'false', 'false', 'true', 'false', 'true', 'false', 'true', 'false', 'true',
            'false', 'true', 'false', 'true', 'false', 'true', 'false', 'true', 'false', 'true',
            'false', 'false', 'false', 'false', 'false'
        ],
        'estimated_owners': [
            '0-20000', '20000-50000', '50000-100000', '100000-200000', '200000-500000',
            '500000-1000000', '1000000-2000000', '2000000-5000000', '5000000-10000000', '10000000-20000000',
            '0-20000', '20000-50000', '50000-100000', '100000-200000', '200000-500000',
            '500000-1000000', '1000000-2000000', '2000000-5000000', '5000000-10000000', '10000000-20000000',
            '0-20000', '50000-100000','10000-20000', '200000-500000', '10000000-20000000'
        ],
        'developers': [
            ['Dev 1'], ['Dev 2'], [], ['Dev 4'], ['Dev 5'], ['Dev 6'], ['Dev 7'], ['Dev 8'], ['Dev 9'], ['Dev 10'],
            ['Dev 11'], ['Dev 12'], [], ['Dev 14'], ['Dev 15'], ['Dev 16'], ['Dev 17'], ['Dev 18'], ['Dev 19'], ['Dev 20'],
             ['Dev 21'], ['Dev 22'], ['Dev 23'],['Dev 24'],['Dev 25']
        ],
        'publishers': [
            ['Pub 1'], ['Pub 2'], [], ['Pub 4'], ['Pub 5'], ['Pub 6'], ['Pub 7'], ['Pub 8'], ['Pub 9'], ['Pub 10'],
            ['Pub 11'], ['Pub 12'], [], ['Pub 14'], ['Pub 15'], ['Pub 16'], ['Pub 17'], ['Pub 18'], ['Pub 19'], ['Pub 20'],
            ['Pub 21'], ['Pub 22'], ['Pub 23'], ['Pub 24'], ['Pub 25']
        ]
    }
    test_df = pd.DataFrame(data)

    data_cleaner = DataCleaner()

    print("---------------------")
    print("üß™ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Å DataFrame:")
    try:
        cleaned_df = data_cleaner.clean_data(test_df)
        print("‚úÖ –û—á–∏—â–µ–Ω–Ω—ã–π DataFrame:")
        print(cleaned_df.head())
    except Exception as e:
          print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ DataFrame: {e}")

    print("---------------------")

    print("üìÑ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Å JSON —Ñ–∞–π–ª–æ–º:")
    try:
        cleaned_df_from_file = data_cleaner.clean_data(raw_data_path)
        print("‚úÖ –û—á–∏—â–µ–Ω–Ω—ã–π DataFrame –∏–∑ JSON —Ñ–∞–π–ª–∞:")
        print(cleaned_df_from_file.head())

        file_handler = FileHandler()
        file_handler.save_data(cleaned_df_from_file, processed_data_path)
        print(f"üíæ –û—á–∏—â–µ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤: {processed_data_path}")

    except FileNotFoundError as e:
         print(f"‚ùå –û—à–∏–±–∫–∞: –§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {e}")
    except Exception as e:
         print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ JSON —Ñ–∞–π–ª–∞: {e}")

    print("---------------------")
    print("‚úÖ –¢–µ—Å—Ç—ã –∑–∞–≤–µ—Ä—à–µ–Ω—ã.")