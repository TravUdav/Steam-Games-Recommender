# Module `src.dataset_cleaner`

## Classes

` class DataCleaner (columns_to_drop=None,  
min_description_length=30,  
max_description_length=240,  
min_tags=3,  
words_to_remove=['game', 'world']) `

     Expand source code
    
    
    class DataCleaner:
        """
        –ö–ª–∞—Å—Å –¥–ª—è –æ—á–∏—Å—Ç–∫–∏ –∏ –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∏ –Ω–∞–±–æ—Ä–∞ –¥–∞–Ω–Ω—ã—Ö –æ–± –∏–≥—Ä–∞—Ö.
    
        –ü—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è–µ—Ç –Ω–∞–±–æ—Ä –º–µ—Ç–æ–¥–æ–≤ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ DataFrame, –≤–∫–ª—é—á–∞—è —É–¥–∞–ª–µ–Ω–∏–µ —Å—Ç–æ–ª–±—Ü–æ–≤,
        —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—é —Å—Ç—Ä–æ–∫ –ø–æ —Ä–∞–∑–ª–∏—á–Ω—ã–º –∫—Ä–∏—Ç–µ—Ä–∏—è–º, –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ —Ç–∏–ø–æ–≤ –¥–∞–Ω–Ω—ã—Ö,
        –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ –∏ –æ—á–∏—Å—Ç–∫—É —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö, —Ç–∞–∫–∏—Ö –∫–∞–∫ –æ–ø–∏—Å–∞–Ω–∏—è –∏ —Ç–µ–≥–∏.
        """
        def __init__(self, columns_to_drop=None, min_description_length=30, max_description_length=240, min_tags=3, words_to_remove = ['game', 'world']):
            """
             –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è DataCleaner.
    
             –ö–æ–Ω—Ñ–∏–≥—É—Ä–∏—Ä—É–µ—Ç –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –æ—á–∏—Å—Ç–∫–∏ –¥–∞–Ω–Ω—ã—Ö, —Ç–∞–∫–∏–µ –∫–∞–∫ —Å–ø–∏—Å–æ–∫ —É–¥–∞–ª—è–µ–º—ã—Ö —Å—Ç–æ–ª–±—Ü–æ–≤,
             –º–∏–Ω–∏–º–∞–ª—å–Ω–∞—è –∏ –º–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –¥–ª–∏–Ω–∞ –æ–ø–∏—Å–∞–Ω–∏–π, –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–µ–≥–æ–≤ –∏ —Å–ø–∏—Å–æ–∫ —Å–ª–æ–≤ –¥–ª—è —É–¥–∞–ª–µ–Ω–∏—è.
             –¢–∞–∫–∂–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ—Ç –ª–µ–º–º–∞—Ç–∏–∑–∞—Ç–æ—Ä—ã –∏ —Å—Ç–æ–ø-—Å–ª–æ–≤–∞ –¥–ª—è –∞–Ω–≥–ª–∏–π—Å–∫–æ–≥–æ –∏ —Ä—É—Å—Å–∫–æ–≥–æ —è–∑—ã–∫–æ–≤.
    
            –ê—Ä–≥—É–º–µ–Ω—Ç—ã:
                columns_to_drop (list, optional): –°–ø–∏—Å–æ–∫ –∏–º–µ–Ω —Å—Ç–æ–ª–±—Ü–æ–≤, –∫–æ—Ç–æ—Ä—ã–µ –±—É–¥—É—Ç —É–¥–∞–ª–µ–Ω—ã –∏–∑ DataFrame.
                                                 –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é None, –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —Å–ø–∏—Å–æ–∫ —Å—Ç–æ–ª–±—Ü–æ–≤ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é.
                min_description_length (int, optional): –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è –¥–ª–∏–Ω–∞ –∫–æ—Ä–æ—Ç–∫–æ–≥–æ –æ–ø–∏—Å–∞–Ω–∏—è –∏–≥—Ä—ã –ø–æ—Å–ª–µ –æ—á–∏—Å—Ç–∫–∏.
                                                        –û–ø–∏—Å–∞–Ω–∏—è –∫–æ—Ä–æ—á–µ —ç—Ç–æ–≥–æ –∑–Ω–∞—á–µ–Ω–∏—è –±—É–¥—É—Ç –æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω—ã. –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é 30.
                max_description_length (int, optional): –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –¥–ª–∏–Ω–∞ –∫–æ—Ä–æ—Ç–∫–æ–≥–æ –æ–ø–∏—Å–∞–Ω–∏—è –∏–≥—Ä—ã –ø–æ—Å–ª–µ –æ—á–∏—Å—Ç–∫–∏.
                                                        –û–ø–∏—Å–∞–Ω–∏—è –¥–ª–∏–Ω–Ω–µ–µ —ç—Ç–æ–≥–æ –∑–Ω–∞—á–µ–Ω–∏—è –±—É–¥—É—Ç –æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω—ã. –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é 240.
                min_tags (int, optional): –ú–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–µ–≥–æ–≤, –∫–æ—Ç–æ—Ä–æ–µ –¥–æ–ª–∂–Ω–∞ —Å–æ–¥–µ—Ä–∂–∞—Ç—å –∏–≥—Ä–∞, —á—Ç–æ–±—ã –æ—Å—Ç–∞—Ç—å—Å—è –≤ –Ω–∞–±–æ—Ä–µ –¥–∞–Ω–Ω—ã—Ö.
                                          –ò–≥—Ä—ã —Å –º–µ–Ω—å—à–∏–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ–º —Ç–µ–≥–æ–≤ –±—É–¥—É—Ç –æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω—ã. –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é 3.
                words_to_remove (list, optional): –°–ø–∏—Å–æ–∫ —Å–ª–æ–≤, –∫–æ—Ç–æ—Ä—ã–µ –±—É–¥—É—Ç —É–¥–∞–ª–µ–Ω—ã –∏–∑ –æ–ø–∏—Å–∞–Ω–∏–π –∏–≥—Ä.
                                                 –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –¥–ª—è —É–¥–∞–ª–µ–Ω–∏—è –æ–±—â–∏—Ö –∏ –Ω–µ–∏–Ω—Ñ–æ—Ä–º–∞—Ç–∏–≤–Ω—ã—Ö —Å–ª–æ–≤. –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é ['game', 'world'].
    
            –í—ã–≤–æ–¥–∏—Ç —Å–æ–æ–±—â–µ–Ω–∏–µ –≤ –∫–æ–Ω—Å–æ–ª—å –æ–± —É—Å–ø–µ—à–Ω–æ–π –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ DataCleaner.
            –ó–∞–≥—Ä—É–∂–∞–µ—Ç –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ —Ä–µ—Å—É—Ä—Å—ã NLTK (stopwords, wordnet) –ø—Ä–∏ –ø–µ—Ä–≤–æ–º –∑–∞–ø—É—Å–∫–µ.
            """
            self.columns_to_drop = columns_to_drop if columns_to_drop else [
                'price', 'dlc_count', 'about_the_game',
                'reviews', 'website', 'support_url',
                'support_email', 'metacritic_score',
                'metacritic_url', 'achievements', 'recommendations',
                'notes', 'full_audio_languages', 'packages',
                'user_score', 'score_rank',
                'screenshots', 'movies',
                'average_playtime_forever', 'average_playtime_2weeks',
                'median_playtime_forever', 'median_playtime_2weeks',
                'peak_ccu'
            ]
            self.min_description_length = min_description_length
            self.max_description_length = max_description_length
            self.min_tags = min_tags
            self.words_to_remove = words_to_remove
            print("‚úÖ DataCleaner –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω.")
    
            try:
                stopwords.words('english')
            except LookupError:
                nltk.download('stopwords')
            try:
                wordnet_lemmatizer = WordNetLemmatizer()
                wordnet_lemmatizer.lemmatize('cats')
            except LookupError:
                nltk.download('wordnet')
                nltk.download('omw-1.4')
    
            self.lemmatizer_en = WordNetLemmatizer()
            self.stop_words_en = set(stopwords.words('english'))
    
            self.morph = pymorphy2.MorphAnalyzer()
            self.stop_words_ru = set(stopwords.words('russian'))
    
    
        def _drop_unnecessary_columns(self, df):
            """–£–¥–∞–ª—è–µ—Ç –∑–∞–¥–∞–Ω–Ω—ã–µ —Å—Ç–æ–ª–±—Ü—ã –∏–∑ DataFrame.
    
            –ò—Å–∫–ª—é—á–∞–µ—Ç –∏–∑ DataFrame —Å—Ç–æ–ª–±—Ü—ã, –ø–µ—Ä–µ—á–∏—Å–ª–µ–Ω–Ω—ã–µ –≤ `self.columns_to_drop`.
            –£–¥–∞–ª–µ–Ω–∏–µ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç—Å—è –Ω–∞ –º–µ—Å—Ç–µ (inplace).
    
            –ê—Ä–≥—É–º–µ–Ω—Ç—ã:
                df (pandas.DataFrame): DataFrame, –∏–∑ –∫–æ—Ç–æ—Ä–æ–≥–æ –Ω—É–∂–Ω–æ —É–¥–∞–ª–∏—Ç—å —Å—Ç–æ–ª–±—Ü—ã.
    
            –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç:
                pandas.DataFrame: DataFrame —Å —É–¥–∞–ª–µ–Ω–Ω—ã–º–∏ —Å—Ç–æ–ª–±—Ü–∞–º–∏.
            """
            initial_shape = df.shape
            columns_to_drop_exist = [col for col in self.columns_to_drop if col in df.columns]
            df.drop(columns=columns_to_drop_exist, inplace=True, errors='ignore')
            return df
    
        def _filter_rows(self, df):
            """
            –§–∏–ª—å—Ç—Ä—É–µ—Ç —Å—Ç—Ä–æ–∫–∏ DataFrame –ø–æ –Ω–∞–±–æ—Ä—É —É—Å–ª–æ–≤–∏–π.
    
            –£–¥–∞–ª—è–µ—Ç —Å—Ç—Ä–æ–∫–∏, –∫–æ—Ç–æ—Ä—ã–µ –Ω–µ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—Ç –∫—Ä–∏—Ç–µ—Ä–∏—è–º –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–≥–æ –∫–∞—á–µ—Å—Ç–≤–∞ –¥–∞–Ω–Ω—ã—Ö,
            —Ç–∞–∫–∏–º –∫–∞–∫ –Ω–∞–ª–∏—á–∏–µ –∫–æ—Ä–æ—Ç–∫–æ–≥–æ –∏ –ø–æ–¥—Ä–æ–±–Ω–æ–≥–æ –æ–ø–∏—Å–∞–Ω–∏—è, –∏–º–µ–Ω–∏, –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è, –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã—Ö —è–∑—ã–∫–æ–≤ –∏ –∫–∞—Ç–µ–≥–æ—Ä–∏–π.
    
            –ê—Ä–≥—É–º–µ–Ω—Ç—ã:
                df (pandas.DataFrame): DataFrame –¥–ª—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏.
    
            –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç:
                pandas.DataFrame: –û—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–Ω—ã–π DataFrame.
            """
            initial_shape = df.shape
    
            mask_to_remove = (
                ((df['short_description'].isna()) | (df['short_description'] == '')) |
                ((df['detailed_description'].isna()) | (df['detailed_description'] == '')) |
                (df['name'].str.contains('playtest', case=False, na=False)) |
                ((df['header_image'].isna()) | (df['header_image'] == '')) |
                (df['supported_languages'].astype(str) == '[]') |
                (df['categories'].astype(str) == '[]')
            )
            df_filtered = df[~mask_to_remove].copy()
            return df_filtered
    
        def _filter_name_chars(self, df):
            """
            –§–∏–ª—å—Ç—Ä—É–µ—Ç DataFrame, –æ—Å—Ç–∞–≤–ª—è—è —Ç–æ–ª—å–∫–æ –∏–≥—Ä—ã —Å –∏–º–µ–Ω–∞–º–∏, —Å–æ–¥–µ—Ä–∂–∞—â–∏–º–∏ –ª–∞—Ç–∏–Ω—Å–∫–∏–µ –±—É–∫–≤—ã, —Ü–∏—Ñ—Ä—ã –∏ –ø—Ä–æ–±–µ–ª—ã.
    
            –£–¥–∞–ª—è–µ—Ç –∏–≥—Ä—ã, –∏–º–µ–Ω–∞ –∫–æ—Ç–æ—Ä—ã—Ö —Å–æ–¥–µ—Ä–∂–∞—Ç —Å–∏–º–≤–æ–ª—ã, –æ—Ç–ª–∏—á–Ω—ã–µ –æ—Ç –ª–∞—Ç–∏–Ω—Å–∫–∏—Ö –±—É–∫–≤, —Ü–∏—Ñ—Ä –∏ –ø—Ä–æ–±–µ–ª–æ–≤,
            –¥–ª—è –æ–±–µ—Å–ø–µ—á–µ–Ω–∏—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏ –∏ —É–ø—Ä–æ—â–µ–Ω–∏—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∏–º–µ–Ω.
    
            –ê—Ä–≥—É–º–µ–Ω—Ç—ã:
                df (pandas.DataFrame): DataFrame –¥–ª—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏.
    
            –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç:
                pandas.DataFrame: –û—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–Ω—ã–π DataFrame.
            """
            initial_shape = df.shape
    
            def clean_name(text):
                 if isinstance(text, str):
                     return re.sub(r'[^a-zA-Z0-9\s]', '', text)
                 return text
    
            df['name'] = df['name'].apply(clean_name)
    
            def is_valid_name(text):
                if isinstance(text, str):
                    return bool(re.fullmatch(r'[a-zA-Z0-9\s]+', text))
                return False
    
            mask_to_remove = ~df['name'].apply(is_valid_name)
            df_filtered = df[~mask_to_remove].copy()
            return df_filtered
    
    
        def _convert_release_date(self, df):
            """
            –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç —Å—Ç–æ–ª–±–µ—Ü 'release_date' –≤ —Ñ–æ—Ä–º–∞—Ç datetime.
    
            –ò—Å–ø–æ–ª—å–∑—É–µ—Ç pandas `to_datetime` –¥–ª—è –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è –¥–∞—Ç –≤—ã–ø—É—Å–∫–∞ –∏–≥—Ä –≤ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç datetime,
            –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—è –æ—à–∏–±–∫–∏ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è –∏ —É—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞—è –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–µ –¥–∞—Ç—ã –≤ NaT (Not a Time).
    
            –ê—Ä–≥—É–º–µ–Ω—Ç—ã:
                df (pandas.DataFrame): DataFrame, —Å–æ–¥–µ—Ä–∂–∞—â–∏–π —Å—Ç–æ–ª–±–µ—Ü 'release_date'.
    
            –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç:
                pandas.DataFrame: DataFrame —Å –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–Ω—ã–º —Å—Ç–æ–ª–±—Ü–æ–º 'release_date'.
            """
            initial_shape = df.shape
            df['release_date'] = pd.to_datetime(df['release_date'], errors='coerce')
            return df
    
        def _convert_bool_columns(self, df):
             """
            –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç —Å—Ç–æ–ª–±—Ü—ã 'windows', 'mac', 'linux' –≤ –±—É–ª–µ–≤—ã–π —Ç–∏–ø –¥–∞–Ω–Ω—ã—Ö.
    
            –ü—Ä–∏–≤–æ–¥–∏—Ç –∑–Ω–∞—á–µ–Ω–∏—è –≤ —Å—Ç–æ–ª–±—Ü–∞—Ö, –æ–±–æ–∑–Ω–∞—á–∞—é—â–∏—Ö –ø–æ–¥–¥–µ—Ä–∂–∫—É –ø–ª–∞—Ç—Ñ–æ—Ä–º, –∫ –±—É–ª–µ–≤–æ–º—É —Ç–∏–ø—É,
            —á—Ç–æ–±—ã —É–ø—Ä–æ—Å—Ç–∏—Ç—å –ª–æ–≥–∏—á–µ—Å–∫–∏–µ –æ–ø–µ—Ä–∞—Ü–∏–∏ –∏ —É–º–µ–Ω—å—à–∏—Ç—å –æ–±—ä–µ–º –ø–∞–º—è—Ç–∏, –∏—Å–ø–æ–ª—å–∑—É–µ–º—ã–π –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è —ç—Ç–∏—Ö –¥–∞–Ω–Ω—ã—Ö.
    
            –ê—Ä–≥—É–º–µ–Ω—Ç—ã:
                df (pandas.DataFrame): DataFrame, —Å–æ–¥–µ—Ä–∂–∞—â–∏–π —Å—Ç–æ–ª–±—Ü—ã –¥–ª—è –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è ('windows', 'mac', 'linux').
    
            Returns:
                pandas.DataFrame: DataFrame —Å –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–Ω—ã–º–∏ –±—É–ª–µ–≤—ã–º–∏ —Å—Ç–æ–ª–±—Ü–∞–º–∏.
            """
             initial_shape = df.shape
             bool_mapping = {'true': True, 'false': False}
             for col in ['windows', 'mac', 'linux']:
                  if col in df.columns:
                    df[col] = df[col].astype(str).str.lower().replace({'nan': None})
                    df[col] = df[col].map(bool_mapping).fillna(False).astype(bool)
             return df
    
        def _extract_owners(self, df):
             """
            –ò–∑–≤–ª–µ–∫–∞–µ—Ç —á–∏—Å–ª–µ–Ω–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ –∏–∑ —Å—Ç–æ–ª–±—Ü–∞ 'estimated_owners'.
    
            –ü–∞—Ä—Å–∏—Ç —Å—Ç–æ–ª–±–µ—Ü 'estimated_owners', –∫–æ—Ç–æ—Ä—ã–π —Å–æ–¥–µ—Ä–∂–∏—Ç –¥–∏–∞–ø–∞–∑–æ–Ω—ã –æ—Ü–µ–Ω–æ—á–Ω–æ–≥–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –≤–ª–∞–¥–µ–ª—å—Ü–µ–≤,
            –∏ –∏–∑–≤–ª–µ–∫–∞–µ—Ç –Ω–∏–∂–Ω—é—é –≥—Ä–∞–Ω–∏—Ü—É –¥–∏–∞–ø–∞–∑–æ–Ω–∞ –∫–∞–∫ —á–∏—Å–ª–µ–Ω–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ, –ø—Ä–∏–≤–æ–¥—è –µ–≥–æ –∫ —Ü–µ–ª–æ–º—É —Ç–∏–ø—É.
    
            –ê—Ä–≥—É–º–µ–Ω—Ç—ã:
                df (pandas.DataFrame): DataFrame, —Å–æ–¥–µ—Ä–∂–∞—â–∏–π —Å—Ç–æ–ª–±–µ—Ü 'estimated_owners'.
    
            –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç:
                pandas.DataFrame: DataFrame —Å –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–Ω—ã–º —Å—Ç–æ–ª–±—Ü–æ–º 'estimated_owners', —Å–æ–¥–µ—Ä–∂–∞—â–∏–º —Ü–µ–ª–æ—á–∏—Å–ª–µ–Ω–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è.
            """
             initial_shape = df.shape
             def extract_first_number(owner_range):
                if isinstance(owner_range, str):
                    parts = owner_range.split(' ', 1)
                    first_part = parts[0].replace(',', '')
                    try:
                       return int(first_part)
                    except ValueError:
                        return None
                return None
    
             df['estimated_owners'] = df['estimated_owners'].apply(extract_first_number)
             return df
    
        def _combine_tags(self, df):
             """
            –û–±—ä–µ–¥–∏–Ω—è–µ—Ç —Ç–µ–≥–∏ –∏–∑ —Å—Ç–æ–ª–±—Ü–æ–≤ 'categories', 'genres' –∏ 'tags' –≤ –æ–¥–∏–Ω —Å—Ç–æ–ª–±–µ—Ü 'all_tags'.
    
            –°–æ–±–∏—Ä–∞–µ—Ç –≤—Å–µ —Ç–µ–≥–∏, –æ—Ç–Ω–æ—Å—è—â–∏–µ—Å—è –∫ –∏–≥—Ä–µ, –∏–∑ —Ä–∞–∑–Ω—ã—Ö —Å—Ç–æ–ª–±—Ü–æ–≤ –∏ —Å–æ–∑–¥–∞–µ—Ç –µ–¥–∏–Ω—ã–π —Å–ø–∏—Å–æ–∫ —Ç–µ–≥–æ–≤ –¥–ª—è –∫–∞–∂–¥–æ–π –∏–≥—Ä—ã,
            —á—Ç–æ–±—ã —É–ø—Ä–æ—Å—Ç–∏—Ç—å –¥–∞–ª—å–Ω–µ–π—à–∏–π –∞–Ω–∞–ª–∏–∑ –∏ –≤–µ–∫—Ç–æ—Ä–∏–∑–∞—Ü–∏—é —Ç–µ–≥–æ–≤.
    
            –ê—Ä–≥—É–º–µ–Ω—Ç—ã:
                df (pandas.DataFrame): DataFrame, —Å–æ–¥–µ—Ä–∂–∞—â–∏–π —Å—Ç–æ–ª–±—Ü—ã 'categories', 'genres' –∏ 'tags'.
    
            –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç:
                pandas.DataFrame: DataFrame —Å –¥–æ–±–∞–≤–ª–µ–Ω–Ω—ã–º —Å—Ç–æ–ª–±—Ü–æ–º 'all_tags', —Å–æ–¥–µ—Ä–∂–∞—â–∏–º —Å–ø–∏—Å–∫–∏ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–Ω—ã—Ö —Ç–µ–≥–æ–≤.
            """
             initial_shape = df.shape
             def combine_tags(row):
                all_tags_list = []
    
                if isinstance(row['categories'], list):
                    all_tags_list.extend(row['categories'])
    
                if isinstance(row['genres'], list):
                    all_tags_list.extend(row['genres'])
    
                if 'tags' in row and isinstance(row['tags'], dict):
                    all_tags_list.extend(row['tags'].keys())
    
                return list(set(all_tags_list))
    
             df['all_tags'] = df.apply(combine_tags, axis=1)
             return df
    
        def _replace_empty_values(self, df):
            """
            –ó–∞–º–µ–Ω—è–µ—Ç –ø—É—Å—Ç—ã–µ —Å–ø–∏—Å–∫–∏ –∏ —Å—Ç—Ä–æ–∫–∏ –≤ —Å—Ç–æ–ª–±—Ü–∞—Ö 'developers' –∏ 'publishers' –Ω–∞ None.
    
            –ù–æ—Ä–º–∞–ª–∏–∑—É–µ—Ç –∑–Ω–∞—á–µ–Ω–∏—è –≤ —Å—Ç–æ–ª–±—Ü–∞—Ö 'developers' –∏ 'publishers', –∑–∞–º–µ–Ω—è—è –ø—É—Å—Ç—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è –Ω–∞ None,
            —á—Ç–æ–±—ã –æ–±–µ—Å–ø–µ—á–∏—Ç—å –µ–¥–∏–Ω–æ–æ–±—Ä–∞–∑–∏–µ –∏ —É–ø—Ä–æ—Å—Ç–∏—Ç—å –æ–±—Ä–∞–±–æ—Ç–∫—É –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—â–∏—Ö –¥–∞–Ω–Ω—ã—Ö.
    
            –ê—Ä–≥—É–º–µ–Ω—Ç—ã:
                df (pandas.DataFrame): DataFrame, —Å–æ–¥–µ—Ä–∂–∞—â–∏–π —Å—Ç–æ–ª–±—Ü—ã 'developers' –∏ 'publishers'.
    
            –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç:
                pandas.DataFrame: DataFrame —Å –∑–∞–º–µ–Ω–µ–Ω–Ω—ã–º–∏ –ø—É—Å—Ç—ã–º–∏ –∑–Ω–∞—á–µ–Ω–∏—è–º–∏ –≤ —Å—Ç–æ–ª–±—Ü–∞—Ö 'developers' –∏ 'publishers'.
            """
            initial_shape = df.shape
            def replace_empty_with_none(series):
                def replace_item(item):
                    if item == [] or item == [''] or item == [""] or item == "":
                        return None
                    return item
    
                return series.apply(replace_item)
    
            if 'developers' in df.columns:
                df['developers'] = replace_empty_with_none(df['developers'])
            if 'publishers' in df.columns:
                df['publishers'] = replace_empty_with_none(df['publishers'])
            return df
    
        def _filter_by_language(self, df):
            """
            –§–∏–ª—å—Ç—Ä—É–µ—Ç DataFrame, –æ—Å—Ç–∞–≤–ª—è—è —Ç–æ–ª—å–∫–æ –æ–ø–∏—Å–∞–Ω–∏—è –Ω–∞ –∞–Ω–≥–ª–∏–π—Å–∫–æ–º –∏–ª–∏ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–∞—Ö.
    
            –ò—Å–ø–æ–ª—å–∑—É–µ—Ç `langdetect` –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —è–∑—ã–∫–∞ –æ–ø–∏—Å–∞–Ω–∏–π –∏–≥—Ä –∏ –æ—Å—Ç–∞–≤–ª—è–µ—Ç —Ç–æ–ª—å–∫–æ —Ç–µ —Å—Ç—Ä–æ–∫–∏,
            –≥–¥–µ –∏ –∫–æ—Ä–æ—Ç–∫–æ–µ, –∏ –ø–æ–¥—Ä–æ–±–Ω–æ–µ –æ–ø–∏—Å–∞–Ω–∏—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω—ã –∫–∞–∫ –∞–Ω–≥–ª–∏–π—Å–∫–∏–µ ('en') –∏–ª–∏ —Ä—É—Å—Å–∫–∏–µ ('ru').
    
            –ê—Ä–≥—É–º–µ–Ω—Ç—ã:
                df (pandas.DataFrame): DataFrame, —Å–æ–¥–µ—Ä–∂–∞—â–∏–π —Å—Ç–æ–ª–±—Ü—ã 'detailed_description' –∏ 'short_description'.
    
            –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç:
                pandas.DataFrame: –û—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–Ω—ã–π DataFrame, —Å–æ–¥–µ—Ä–∂–∞—â–∏–π —Ç–æ–ª—å–∫–æ –æ–ø–∏—Å–∞–Ω–∏—è –Ω–∞ –∞–Ω–≥–ª–∏–π—Å–∫–æ–º –∏–ª–∏ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–∞—Ö.
            """
            initial_shape = df.shape
    
            def is_english_or_russian(text):
               if not isinstance(text, str):
                    return False
               try:
                    lang = detect(text)
                    return lang == 'en' or lang == 'ru'
               except LangDetectException:
                   return False
    
            df['detailed_is_en_ru'] = df['detailed_description'].apply(is_english_or_russian)
            df['short_is_en_ru'] = df['short_description'].apply(is_english_or_russian)
    
            df_filtered = df[df['detailed_is_en_ru'] & df['short_is_en_ru']].copy()
            df_filtered = df_filtered.drop(columns=['detailed_is_en_ru', 'short_is_en_ru'], errors='ignore')
            return df_filtered
    
        def _clean_and_lemmatize_descriptions(self, df):
            """
            –û—á–∏—â–∞–µ—Ç –∏ –ª–µ–º–º–∞—Ç–∏–∑–∏—Ä—É–µ—Ç —Ç–µ–∫—Å—Ç–æ–≤—ã–µ –æ–ø–∏—Å–∞–Ω–∏—è –∏–≥—Ä.
    
            –ü—Ä–∏–º–µ–Ω—è–µ—Ç –æ—á–∏—Å—Ç–∫—É —Ç–µ–∫—Å—Ç–∞, –≤–∫–ª—é—á–∞—è –ø—Ä–∏–≤–µ–¥–µ–Ω–∏–µ –∫ –Ω–∏–∂–Ω–µ–º—É —Ä–µ–≥–∏—Å—Ç—Ä—É, —É–¥–∞–ª–µ–Ω–∏–µ –∑–Ω–∞–∫–æ–≤ –ø—É–Ω–∫—Ç—É–∞—Ü–∏–∏ –∏ —Ü–∏—Ñ—Ä,
            –∞ —Ç–∞–∫–∂–µ –ª–µ–º–º–∞—Ç–∏–∑–∞—Ü–∏—é —Å–ª–æ–≤ –¥–ª—è –∞–Ω–≥–ª–∏–π—Å–∫–æ–≥–æ –∏ —Ä—É—Å—Å–∫–æ–≥–æ —è–∑—ã–∫–æ–≤ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º NLTK –∏ pymorphy2.
    
            –ê—Ä–≥—É–º–µ–Ω—Ç—ã:
                df (pandas.DataFrame): DataFrame, —Å–æ–¥–µ—Ä–∂–∞—â–∏–π —Å—Ç–æ–ª–±—Ü—ã 'detailed_description' –∏ 'short_description'.
    
            –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç:
                pandas.DataFrame: DataFrame —Å –¥–æ–±–∞–≤–ª–µ–Ω–Ω—ã–º–∏ —Å—Ç–æ–ª–±—Ü–∞–º–∏ '_clean' –¥–ª—è –æ—á–∏—â–µ–Ω–Ω—ã—Ö –æ–ø–∏—Å–∞–Ω–∏–π ('detailed_description_clean', 'short_description_clean').
            """
            initial_shape = df.shape
    
            def clean_and_lemmatize(text, lang='en'):
                if not isinstance(text, str):
                    return ""
    
                text = text.lower()
                text = re.sub(r'[^\w\s]', '', text)
                text = re.sub(r'\d+', '', text)
    
                words = text.split()
    
                if lang == 'ru':
                    lemmatized_words = [self.morph.parse(word)[0].normal_form for word in words if word not in self.stop_words_ru]
                else:
                    lemmatized_words = [self.lemmatizer_en.lemmatize(word) for word in words if word not in self.stop_words_en]
    
                return " ".join(lemmatized_words)
    
            df['detailed_description_clean'] = df['detailed_description'].apply(lambda x: clean_and_lemmatize(x))
            df['short_description_clean'] = df['short_description'].apply(lambda x: clean_and_lemmatize(x))
            return df
    
        def _remove_specific_words_from_descriptions(self, df):
            """
            –£–¥–∞–ª—è–µ—Ç –∑–∞–¥–∞–Ω–Ω—ã–µ —Å–ª–æ–≤–∞ –∏–∑ –æ—á–∏—â–µ–Ω–Ω—ã—Ö –æ–ø–∏—Å–∞–Ω–∏–π –∏–≥—Ä.
    
            –ò—Å–∫–ª—é—á–∞–µ—Ç —Å–ª–æ–≤–∞, –ø–µ—Ä–µ—á–∏—Å–ª–µ–Ω–Ω—ã–µ –≤ `self.words_to_remove`, –∏–∑ –æ—á–∏—â–µ–Ω–Ω—ã—Ö –∫–æ—Ä–æ—Ç–∫–∏—Ö –∏ –ø–æ–¥—Ä–æ–±–Ω—ã—Ö –æ–ø–∏—Å–∞–Ω–∏–π –∏–≥—Ä,
            —á—Ç–æ–±—ã —É–±—Ä–∞—Ç—å –æ–±—â–∏–µ –∏ –Ω–µ—Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ —Å–ª–æ–≤–∞, —Å–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã–µ –¥–ª—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –∏–≥—Ä.
    
            –ê—Ä–≥—É–º–µ–Ω—Ç—ã:
                df (pandas.DataFrame): DataFrame, —Å–æ–¥–µ—Ä–∂–∞—â–∏–π —Å—Ç–æ–ª–±—Ü—ã 'short_description_clean' –∏ 'detailed_description_clean'.
    
            –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç:
                pandas.DataFrame: DataFrame —Å —É–¥–∞–ª–µ–Ω–Ω—ã–º–∏ —Å–ø–µ—Ü–∏—Ñ–∏—á–µ—Å–∫–∏–º–∏ —Å–ª–æ–≤–∞–º–∏ –∏–∑ –æ—á–∏—â–µ–Ω–Ω—ã—Ö –æ–ø–∏—Å–∞–Ω–∏–π.
            """
            initial_shape = df.shape
            def remove_words(text):
                if isinstance(text, str):
                    words = text.split()
                    filtered_words = [word for word in words if word not in self.words_to_remove]
                    return ' '.join(filtered_words)
                return text
    
            df['short_description_clean'] = df['short_description_clean'].apply(remove_words)
            df['detailed_description_clean'] = df['detailed_description_clean'].apply(remove_words)
            return df
    
        def _filter_description_length(self, df):
            """
            –§–∏–ª—å—Ç—Ä—É–µ—Ç DataFrame –ø–æ –¥–ª–∏–Ω–µ –æ—á–∏—â–µ–Ω–Ω—ã—Ö –∫–æ—Ä–æ—Ç–∫–∏—Ö –æ–ø–∏—Å–∞–Ω–∏–π.
    
            –£–¥–∞–ª—è–µ—Ç —Å—Ç—Ä–æ–∫–∏, –≥–¥–µ –¥–ª–∏–Ω–∞ –æ—á–∏—â–µ–Ω–Ω–æ–≥–æ –∫–æ—Ä–æ—Ç–∫–æ–≥–æ –æ–ø–∏—Å–∞–Ω–∏—è –Ω–µ –ø–æ–ø–∞–¥–∞–µ—Ç –≤ –∑–∞–¥–∞–Ω–Ω—ã–π –¥–∏–∞–ø–∞–∑–æ–Ω
            (`self.min_description_length` –∏ `self.max_description_length`), —á—Ç–æ–±—ã –æ–±–µ—Å–ø–µ—á–∏—Ç—å –º–∏–Ω–∏–º–∞–ª—å–Ω—É—é –∏ –º–∞–∫—Å–∏–º–∞–ª—å–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ç–∏–≤–Ω–æ—Å—Ç—å –æ–ø–∏—Å–∞–Ω–∏–π.
    
            –ê—Ä–≥—É–º–µ–Ω—Ç—ã:
                df (pandas.DataFrame): DataFrame, —Å–æ–¥–µ—Ä–∂–∞—â–∏–π —Å—Ç–æ–ª–±–µ—Ü 'short_description_clean'.
    
            –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç:
                pandas.DataFrame: –û—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–Ω—ã–π DataFrame, —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–π –∑–∞–¥–∞–Ω–Ω—ã–º –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è–º –ø–æ –¥–ª–∏–Ω–µ –æ–ø–∏—Å–∞–Ω–∏–π.
            """
            initial_shape = df.shape
            if isinstance(data, str):
                df_filtered = df[(df['short_description_clean'].str.len() >= self.min_description_length) & (df['short_description_clean'].str.len() <= self.max_description_length)].copy()
            else:
                df_filtered = df.copy()
            return df_filtered
    
        def _clean_and_lowercase_tags(self, df):
            """
            –û—á–∏—â–∞–µ—Ç –∏ –ø—Ä–∏–≤–æ–¥–∏—Ç –∫ –Ω–∏–∂–Ω–µ–º—É —Ä–µ–≥–∏—Å—Ç—Ä—É —Ç–µ–≥–∏ –≤ —Å—Ç–æ–ª–±—Ü–µ 'all_tags'.
    
            –£–¥–∞–ª—è–µ—Ç –∏–∑ —Ç–µ–≥–æ–≤ —Å–∏–º–≤–æ–ª—ã, –Ω–µ —è–≤–ª—è—é—â–∏–µ—Å—è –±—É–∫–≤–∞–º–∏ –∏–ª–∏ —Ü–∏—Ñ—Ä–∞–º–∏, –ø—Ä–∏–≤–æ–¥–∏—Ç –≤—Å–µ —Ç–µ–≥–∏ –∫ –Ω–∏–∂–Ω–µ–º—É —Ä–µ–≥–∏—Å—Ç—Ä—É
            –∏ —É–¥–∞–ª—è–µ—Ç –ª–∏—à–Ω–∏–µ –ø—Ä–æ–±–µ–ª—ã, –æ–±–µ—Å–ø–µ—á–∏–≤–∞—è —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π –∏ –æ—á–∏—â–µ–Ω–Ω—ã–π –≤–∏–¥ —Ç–µ–≥–æ–≤.
    
            –ê—Ä–≥—É–º–µ–Ω—Ç—ã:
                df (pandas.DataFrame): DataFrame, —Å–æ–¥–µ—Ä–∂–∞—â–∏–π —Å—Ç–æ–ª–±–µ—Ü 'all_tags'.
    
            –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç:
                pandas.DataFrame: DataFrame —Å –æ—á–∏—â–µ–Ω–Ω—ã–º–∏ –∏ –ø—Ä–∏–≤–µ–¥–µ–Ω–Ω—ã–º–∏ –∫ –Ω–∏–∂–Ω–µ–º—É —Ä–µ–≥–∏—Å—Ç—Ä—É —Ç–µ–≥–∞–º–∏.
            """
            initial_shape = df.shape
            def clean_tags(tags):
                if isinstance(tags, list):
                    cleaned_tags = [re.sub(r'[^a-zA-Z0-9\s]', '', tag).lower().strip() for tag in tags]
                    return cleaned_tags
                return tags
    
            df['all_tags'] = df['all_tags'].apply(clean_tags)
            return df
    
        def _filter_tags_count(self, df):
            """
            –§–∏–ª—å—Ç—Ä—É–µ—Ç DataFrame –ø–æ –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–º—É –∫–æ–ª–∏—á–µ—Å—Ç–≤—É —Ç–µ–≥–æ–≤ –≤ —Å—Ç–æ–ª–±—Ü–µ 'all_tags'.
    
            –£–¥–∞–ª—è–µ—Ç —Å—Ç—Ä–æ–∫–∏, –≥–¥–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–µ–≥–æ–≤ –≤ —Å–ø–∏—Å–∫–µ 'all_tags' –º–µ–Ω—å—à–µ, —á–µ–º –∑–∞–¥–∞–Ω–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ `self.min_tags`,
            —á—Ç–æ–±—ã –æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞—Ç—å –∏–≥—Ä—ã —Å –Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω—ã–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ–º —Ç–µ–≥–æ–≤ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞.
    
            –ê—Ä–≥—É–º–µ–Ω—Ç—ã:
                df (pandas.DataFrame): DataFrame, —Å–æ–¥–µ—Ä–∂–∞—â–∏–π —Å—Ç–æ–ª–±–µ—Ü 'all_tags'.
    
            –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç:
                pandas.DataFrame: –û—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–Ω—ã–π DataFrame, —Å–æ–¥–µ—Ä–∂–∞—â–∏–π —Ç–æ–ª—å–∫–æ –∏–≥—Ä—ã —Å –¥–æ—Å—Ç–∞—Ç–æ—á–Ω—ã–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ–º —Ç–µ–≥–æ–≤.
            """
            initial_shape = df.shape
            df_filtered = df[df['all_tags'].apply(lambda x: isinstance(x, list) and len(x) >= self.min_tags)].copy()
            return df_filtered
    
        def clean_data(self, data):
             """
            –ö–æ–æ—Ä–¥–∏–Ω–∏—Ä—É–µ—Ç –ø—Ä–æ—Ü–µ—Å—Å –æ—á–∏—Å—Ç–∫–∏ –¥–∞–Ω–Ω—ã—Ö DataFrame.
    
            –í—ã–∑—ã–≤–∞–µ—Ç –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ –≤—Å–µ –º–µ—Ç–æ–¥—ã –æ—á–∏—Å—Ç–∫–∏ –¥–∞–Ω–Ω—ã—Ö, –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω—ã–µ –≤ –∫–ª–∞—Å—Å–µ,
            –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ DataFrame –∏ –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∏ –¥–∞–Ω–Ω—ã—Ö –∫ –¥–∞–ª—å–Ω–µ–π—à–µ–º—É –∞–Ω–∞–ª–∏–∑—É –∏–ª–∏ –º–æ–¥–µ–ª–∏—Ä–æ–≤–∞–Ω–∏—é.
            –ú–µ—Ç–æ–¥ –º–æ–∂–µ—Ç –ø—Ä–∏–Ω–∏–º–∞—Ç—å –∫–∞–∫ DataFrame, —Ç–∞–∫ –∏ –ø—É—Ç—å –∫ —Ñ–∞–π–ª—É —Å –¥–∞–Ω–Ω—ã–º–∏.
    
            –ê—Ä–≥—É–º–µ–Ω—Ç—ã:
                data (pandas.DataFrame –∏–ª–∏ str): DataFrame –¥–ª—è –æ—á–∏—Å—Ç–∫–∏ –∏–ª–∏ –ø—É—Ç—å –∫ —Ñ–∞–π–ª—É (JSON, CSV), –∫–æ—Ç–æ—Ä—ã–π –Ω—É–∂–Ω–æ –∑–∞–≥—Ä—É–∑–∏—Ç—å –∏ –æ—á–∏—Å—Ç–∏—Ç—å.
    
            –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç:
                pandas.DataFrame: –û—á–∏—â–µ–Ω–Ω—ã–π DataFrame.
    
            –í—ã–∑—ã–≤–∞–µ—Ç:
                ValueError: –ï—Å–ª–∏ –≤—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –Ω–µ —è–≤–ª—è—é—Ç—Å—è DataFrame –∏ –Ω–µ —Å—Ç—Ä–æ–∫–æ–π (–ø—É—Ç–µ–º –∫ —Ñ–∞–π–ª—É).
    
            –í—ã–≤–æ–¥–∏—Ç –≤ –∫–æ–Ω—Å–æ–ª—å —Å–æ–æ–±—â–µ–Ω–∏—è –æ –Ω–∞—á–∞–ª–µ –∏ –∑–∞–≤–µ—Ä—à–µ–Ω–∏–∏ –ø—Ä–æ—Ü–µ—Å—Å–∞ –æ—á–∏—Å—Ç–∫–∏, –∞ —Ç–∞–∫–∂–µ –Ω–∞—á–∞–ª—å–Ω—É—é –∏ –∫–æ–Ω–µ—á–Ω—É—é —Ñ–æ—Ä–º—É DataFrame.
            """
             print("üßπ –ù–∞—á–∏–Ω–∞–µ—Ç—Å—è –ø—Ä–æ—Ü–µ—Å—Å –æ—á–∏—Å—Ç–∫–∏ –¥–∞–Ω–Ω—ã—Ö...")
             if isinstance(data, str):
                  file_handler = FileHandler()
                  df = file_handler.load_data(data)
                  apply_description_length_filter = True
             elif isinstance(data, pd.DataFrame):
                 df = data.copy()
                 apply_description_length_filter = False
             else:
                 raise ValueError("‚ùå –í—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å pandas DataFrame –∏–ª–∏ –ø—É—Ç–µ–º –∫ —Ñ–∞–π–ª—É.")
    
             initial_shape = df.shape
             print(f"üìä –ò—Å—Ö–æ–¥–Ω–∞—è —Ñ–æ—Ä–º–∞ DataFrame –ø–µ—Ä–µ–¥ –æ—á–∏—Å—Ç–∫–æ–π: {initial_shape}")
    
             df = self._filter_rows(df)
             df = self._combine_tags(df)
             df = self._drop_unnecessary_columns(df)
             df = self._filter_name_chars(df)
             df = self._convert_release_date(df)
             df = self._convert_bool_columns(df)
             df = self._extract_owners(df)
             df = self._replace_empty_values(df)
             df = self._filter_by_language(df)
             df = self._clean_and_lemmatize_descriptions(df)
             df = self._remove_specific_words_from_descriptions(df)
             if apply_description_length_filter:
                df = self._filter_description_length(df)
             df = self._clean_and_lowercase_tags(df)
             df = self._filter_tags_count(df)
    
             print(f"‚úÖ –ü—Ä–æ—Ü–µ—Å—Å –æ—á–∏—Å—Ç–∫–∏ –¥–∞–Ω–Ω—ã—Ö –∑–∞–≤–µ—Ä—à–µ–Ω. –ò—Ç–æ–≥–æ–≤–∞—è —Ñ–æ—Ä–º–∞: {df.shape}")
             return df

–ö–ª–∞—Å—Å –¥–ª—è –æ—á–∏—Å—Ç–∫–∏ –∏ –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∏ –Ω–∞–±–æ—Ä–∞ –¥–∞–Ω–Ω—ã—Ö –æ–± –∏–≥—Ä–∞—Ö.

–ü—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è–µ—Ç –Ω–∞–±–æ—Ä –º–µ—Ç–æ–¥–æ–≤ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ DataFrame, –≤–∫–ª—é—á–∞—è —É–¥–∞–ª–µ–Ω–∏–µ
—Å—Ç–æ–ª–±—Ü–æ–≤, —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—é —Å—Ç—Ä–æ–∫ –ø–æ —Ä–∞–∑–ª–∏—á–Ω—ã–º –∫—Ä–∏—Ç–µ—Ä–∏—è–º, –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ —Ç–∏–ø–æ–≤
–¥–∞–Ω–Ω—ã—Ö, –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ –∏ –æ—á–∏—Å—Ç–∫—É —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö, —Ç–∞–∫–∏—Ö –∫–∞–∫ –æ–ø–∏—Å–∞–Ω–∏—è –∏ —Ç–µ–≥–∏.

–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è DataCleaner.

–ö–æ–Ω—Ñ–∏–≥—É—Ä–∏—Ä—É–µ—Ç –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –æ—á–∏—Å—Ç–∫–∏ –¥–∞–Ω–Ω—ã—Ö, —Ç–∞–∫–∏–µ –∫–∞–∫ —Å–ø–∏—Å–æ–∫ —É–¥–∞–ª—è–µ–º—ã—Ö —Å—Ç–æ–ª–±—Ü–æ–≤,
–º–∏–Ω–∏–º–∞–ª—å–Ω–∞—è –∏ –º–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –¥–ª–∏–Ω–∞ –æ–ø–∏—Å–∞–Ω–∏–π, –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–µ–≥–æ–≤ –∏
—Å–ø–∏—Å–æ–∫ —Å–ª–æ–≤ –¥–ª—è —É–¥–∞–ª–µ–Ω–∏—è. –¢–∞–∫–∂–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ—Ç –ª–µ–º–º–∞—Ç–∏–∑–∞—Ç–æ—Ä—ã –∏ —Å—Ç–æ–ø-—Å–ª–æ–≤–∞ –¥–ª—è
–∞–Ω–≥–ª–∏–π—Å–∫–æ–≥–æ –∏ —Ä—É—Å—Å–∫–æ–≥–æ —è–∑—ã–∫–æ–≤.

–ê—Ä–≥—É–º–µ–Ω—Ç—ã: columns_to_drop (list, optional): –°–ø–∏—Å–æ–∫ –∏–º–µ–Ω —Å—Ç–æ–ª–±—Ü–æ–≤, –∫–æ—Ç–æ—Ä—ã–µ
–±—É–¥—É—Ç —É–¥–∞–ª–µ–Ω—ã –∏–∑ DataFrame. –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é None, –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —Å–ø–∏—Å–æ–∫ —Å—Ç–æ–ª–±—Ü–æ–≤ –ø–æ
—É–º–æ–ª—á–∞–Ω–∏—é. min_description_length (int, optional): –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è –¥–ª–∏–Ω–∞ –∫–æ—Ä–æ—Ç–∫–æ–≥–æ
–æ–ø–∏—Å–∞–Ω–∏—è –∏–≥—Ä—ã –ø–æ—Å–ª–µ –æ—á–∏—Å—Ç–∫–∏. –û–ø–∏—Å–∞–Ω–∏—è –∫–æ—Ä–æ—á–µ —ç—Ç–æ–≥–æ –∑–Ω–∞—á–µ–Ω–∏—è –±—É–¥—É—Ç
–æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω—ã. –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é 30. max_description_length (int, optional):
–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –¥–ª–∏–Ω–∞ –∫–æ—Ä–æ—Ç–∫–æ–≥–æ –æ–ø–∏—Å–∞–Ω–∏—è –∏–≥—Ä—ã –ø–æ—Å–ª–µ –æ—á–∏—Å—Ç–∫–∏. –û–ø–∏—Å–∞–Ω–∏—è –¥–ª–∏–Ω–Ω–µ–µ
—ç—Ç–æ–≥–æ –∑–Ω–∞—á–µ–Ω–∏—è –±—É–¥—É—Ç –æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω—ã. –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é 240. min_tags (int,
optional): –ú–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–µ–≥–æ–≤, –∫–æ—Ç–æ—Ä–æ–µ –¥–æ–ª–∂–Ω–∞ —Å–æ–¥–µ—Ä–∂–∞—Ç—å –∏–≥—Ä–∞, —á—Ç–æ–±—ã
–æ—Å—Ç–∞—Ç—å—Å—è –≤ –Ω–∞–±–æ—Ä–µ –¥–∞–Ω–Ω—ã—Ö. –ò–≥—Ä—ã —Å –º–µ–Ω—å—à–∏–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ–º —Ç–µ–≥–æ–≤ –±—É–¥—É—Ç
–æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω—ã. –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é 3. words_to_remove (list, optional): –°–ø–∏—Å–æ–∫ —Å–ª–æ–≤,
–∫–æ—Ç–æ—Ä—ã–µ –±—É–¥—É—Ç —É–¥–∞–ª–µ–Ω—ã –∏–∑ –æ–ø–∏—Å–∞–Ω–∏–π –∏–≥—Ä. –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –¥–ª—è —É–¥–∞–ª–µ–Ω–∏—è –æ–±—â–∏—Ö –∏
–Ω–µ–∏–Ω—Ñ–æ—Ä–º–∞—Ç–∏–≤–Ω—ã—Ö —Å–ª–æ–≤. –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é ['game', 'world'].

–í—ã–≤–æ–¥–∏—Ç —Å–æ–æ–±—â–µ–Ω–∏–µ –≤ –∫–æ–Ω—Å–æ–ª—å –æ–± —É—Å–ø–µ—à–Ω–æ–π –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ DataCleaner. –ó–∞–≥—Ä—É–∂–∞–µ—Ç
–Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ —Ä–µ—Å—É—Ä—Å—ã NLTK (stopwords, wordnet) –ø—Ä–∏ –ø–µ—Ä–≤–æ–º –∑–∞–ø—É—Å–∫–µ.

### Methods

` def clean_data(self, data) `

     Expand source code
    
    
    def clean_data(self, data):
         """
        –ö–æ–æ—Ä–¥–∏–Ω–∏—Ä—É–µ—Ç –ø—Ä–æ—Ü–µ—Å—Å –æ—á–∏—Å—Ç–∫–∏ –¥–∞–Ω–Ω—ã—Ö DataFrame.
    
        –í—ã–∑—ã–≤–∞–µ—Ç –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ –≤—Å–µ –º–µ—Ç–æ–¥—ã –æ—á–∏—Å—Ç–∫–∏ –¥–∞–Ω–Ω—ã—Ö, –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω—ã–µ –≤ –∫–ª–∞—Å—Å–µ,
        –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ DataFrame –∏ –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∏ –¥–∞–Ω–Ω—ã—Ö –∫ –¥–∞–ª—å–Ω–µ–π—à–µ–º—É –∞–Ω–∞–ª–∏–∑—É –∏–ª–∏ –º–æ–¥–µ–ª–∏—Ä–æ–≤–∞–Ω–∏—é.
        –ú–µ—Ç–æ–¥ –º–æ–∂–µ—Ç –ø—Ä–∏–Ω–∏–º–∞—Ç—å –∫–∞–∫ DataFrame, —Ç–∞–∫ –∏ –ø—É—Ç—å –∫ —Ñ–∞–π–ª—É —Å –¥–∞–Ω–Ω—ã–º–∏.
    
        –ê—Ä–≥—É–º–µ–Ω—Ç—ã:
            data (pandas.DataFrame –∏–ª–∏ str): DataFrame –¥–ª—è –æ—á–∏—Å—Ç–∫–∏ –∏–ª–∏ –ø—É—Ç—å –∫ —Ñ–∞–π–ª—É (JSON, CSV), –∫–æ—Ç–æ—Ä—ã–π –Ω—É–∂–Ω–æ –∑–∞–≥—Ä—É–∑–∏—Ç—å –∏ –æ—á–∏—Å—Ç–∏—Ç—å.
    
        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç:
            pandas.DataFrame: –û—á–∏—â–µ–Ω–Ω—ã–π DataFrame.
    
        –í—ã–∑—ã–≤–∞–µ—Ç:
            ValueError: –ï—Å–ª–∏ –≤—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –Ω–µ —è–≤–ª—è—é—Ç—Å—è DataFrame –∏ –Ω–µ —Å—Ç—Ä–æ–∫–æ–π (–ø—É—Ç–µ–º –∫ —Ñ–∞–π–ª—É).
    
        –í—ã–≤–æ–¥–∏—Ç –≤ –∫–æ–Ω—Å–æ–ª—å —Å–æ–æ–±—â–µ–Ω–∏—è –æ –Ω–∞—á–∞–ª–µ –∏ –∑–∞–≤–µ—Ä—à–µ–Ω–∏–∏ –ø—Ä–æ—Ü–µ—Å—Å–∞ –æ—á–∏—Å—Ç–∫–∏, –∞ —Ç–∞–∫–∂–µ –Ω–∞—á–∞–ª—å–Ω—É—é –∏ –∫–æ–Ω–µ—á–Ω—É—é —Ñ–æ—Ä–º—É DataFrame.
        """
         print("üßπ –ù–∞—á–∏–Ω–∞–µ—Ç—Å—è –ø—Ä–æ—Ü–µ—Å—Å –æ—á–∏—Å—Ç–∫–∏ –¥–∞–Ω–Ω—ã—Ö...")
         if isinstance(data, str):
              file_handler = FileHandler()
              df = file_handler.load_data(data)
              apply_description_length_filter = True
         elif isinstance(data, pd.DataFrame):
             df = data.copy()
             apply_description_length_filter = False
         else:
             raise ValueError("‚ùå –í—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å pandas DataFrame –∏–ª–∏ –ø—É—Ç–µ–º –∫ —Ñ–∞–π–ª—É.")
    
         initial_shape = df.shape
         print(f"üìä –ò—Å—Ö–æ–¥–Ω–∞—è —Ñ–æ—Ä–º–∞ DataFrame –ø–µ—Ä–µ–¥ –æ—á–∏—Å—Ç–∫–æ–π: {initial_shape}")
    
         df = self._filter_rows(df)
         df = self._combine_tags(df)
         df = self._drop_unnecessary_columns(df)
         df = self._filter_name_chars(df)
         df = self._convert_release_date(df)
         df = self._convert_bool_columns(df)
         df = self._extract_owners(df)
         df = self._replace_empty_values(df)
         df = self._filter_by_language(df)
         df = self._clean_and_lemmatize_descriptions(df)
         df = self._remove_specific_words_from_descriptions(df)
         if apply_description_length_filter:
            df = self._filter_description_length(df)
         df = self._clean_and_lowercase_tags(df)
         df = self._filter_tags_count(df)
    
         print(f"‚úÖ –ü—Ä–æ—Ü–µ—Å—Å –æ—á–∏—Å—Ç–∫–∏ –¥–∞–Ω–Ω—ã—Ö –∑–∞–≤–µ—Ä—à–µ–Ω. –ò—Ç–æ–≥–æ–≤–∞—è —Ñ–æ—Ä–º–∞: {df.shape}")
         return df

–ö–æ–æ—Ä–¥–∏–Ω–∏—Ä—É–µ—Ç –ø—Ä–æ—Ü–µ—Å—Å –æ—á–∏—Å—Ç–∫–∏ –¥–∞–Ω–Ω—ã—Ö DataFrame.

–í—ã–∑—ã–≤–∞–µ—Ç –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ –≤—Å–µ –º–µ—Ç–æ–¥—ã –æ—á–∏—Å—Ç–∫–∏ –¥–∞–Ω–Ω—ã—Ö, –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω—ã–µ –≤ –∫–ª–∞—Å—Å–µ, –¥–ª—è
–æ–±—Ä–∞–±–æ—Ç–∫–∏ DataFrame –∏ –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∏ –¥–∞–Ω–Ω—ã—Ö –∫ –¥–∞–ª—å–Ω–µ–π—à–µ–º—É –∞–Ω–∞–ª–∏–∑—É –∏–ª–∏
–º–æ–¥–µ–ª–∏—Ä–æ–≤–∞–Ω–∏—é. –ú–µ—Ç–æ–¥ –º–æ–∂–µ—Ç –ø—Ä–∏–Ω–∏–º–∞—Ç—å –∫–∞–∫ DataFrame, —Ç–∞–∫ –∏ –ø—É—Ç—å –∫ —Ñ–∞–π–ª—É —Å
–¥–∞–Ω–Ω—ã–º–∏.

–ê—Ä–≥—É–º–µ–Ω—Ç—ã: data (pandas.DataFrame –∏–ª–∏ str): DataFrame –¥–ª—è –æ—á–∏—Å—Ç–∫–∏ –∏–ª–∏ –ø—É—Ç—å –∫
—Ñ–∞–π–ª—É (JSON, CSV), –∫–æ—Ç–æ—Ä—ã–π –Ω—É–∂–Ω–æ –∑–∞–≥—Ä—É–∑–∏—Ç—å –∏ –æ—á–∏—Å—Ç–∏—Ç—å.

–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç: pandas.DataFrame: –û—á–∏—â–µ–Ω–Ω—ã–π DataFrame.

–í—ã–∑—ã–≤–∞–µ—Ç: ValueError: –ï—Å–ª–∏ –≤—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –Ω–µ —è–≤–ª—è—é—Ç—Å—è DataFrame –∏ –Ω–µ —Å—Ç—Ä–æ–∫–æ–π
(–ø—É—Ç–µ–º –∫ —Ñ–∞–π–ª—É).

–í—ã–≤–æ–¥–∏—Ç –≤ –∫–æ–Ω—Å–æ–ª—å —Å–æ–æ–±—â–µ–Ω–∏—è –æ –Ω–∞—á–∞–ª–µ –∏ –∑–∞–≤–µ—Ä—à–µ–Ω–∏–∏ –ø—Ä–æ—Ü–µ—Å—Å–∞ –æ—á–∏—Å—Ç–∫–∏, –∞ —Ç–∞–∫–∂–µ
–Ω–∞—á–∞–ª—å–Ω—É—é –∏ –∫–æ–Ω–µ—á–Ω—É—é —Ñ–æ—Ä–º—É DataFrame.

` class FileHandler `

     Expand source code
    
    
    class FileHandler:
        """
        –ö–ª–∞—Å—Å –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –æ–ø–µ—Ä–∞—Ü–∏–π –∑–∞–≥—Ä—É–∑–∫–∏ –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö –∏–∑ —Ñ–∞–π–ª–æ–≤ JSON –∏ CSV.
    
        –ü—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è–µ—Ç –º–µ—Ç–æ–¥—ã –¥–ª—è —á—Ç–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö –∏–∑ —Ñ–∞–π–ª–æ–≤ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö —Ñ–æ—Ä–º–∞—Ç–æ–≤, —Ç–∞–∫–∏—Ö –∫–∞–∫ JSON –∏ CSV,
        –≤ pandas DataFrame, –∞ —Ç–∞–∫–∂–µ –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è DataFrame –æ–±—Ä–∞—Ç–Ω–æ –≤ —Ñ–∞–π–ª—ã JSON –∏–ª–∏ CSV.
        """
        def __init__(self):
            """
            –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è FileHandler.
    
            –í—ã–≤–æ–¥–∏—Ç —Å–æ–æ–±—â–µ–Ω–∏–µ –≤ –∫–æ–Ω—Å–æ–ª—å –æ–± —É—Å–ø–µ—à–Ω–æ–π –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ FileHandler.
            """
            print("‚úÖ FileHandler –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω.")
    
        def load_data(self, path):
            """
            –ó–∞–≥—Ä—É–∂–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –∏–∑ —Ñ–∞–π–ª–∞ JSON –∏–ª–∏ CSV –≤ pandas DataFrame.
    
            –û–ø—Ä–µ–¥–µ–ª—è–µ—Ç —Ç–∏–ø —Ñ–∞–π–ª–∞ –ø–æ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—é –∏ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–π –º–µ—Ç–æ–¥ pandas –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ –¥–∞–Ω–Ω—ã—Ö.
            –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç —Ñ–∞–π–ª—ã —Å —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—è–º–∏ .json, .csv –∏ .txt.
    
            –ê—Ä–≥—É–º–µ–Ω—Ç—ã:
                path (str): –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É, –∏–∑ –∫–æ—Ç–æ—Ä–æ–≥–æ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ –∑–∞–≥—Ä—É–∑–∏—Ç—å –¥–∞–Ω–Ω—ã–µ.
    
            –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç:
                pandas.DataFrame: DataFrame, —Å–æ–¥–µ—Ä–∂–∞—â–∏–π –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ.
    
            –í—ã–∑—ã–≤–∞–µ—Ç:
                FileNotFoundError: –ï—Å–ª–∏ —Ñ–∞–π–ª –ø–æ —É–∫–∞–∑–∞–Ω–Ω–æ–º—É –ø—É—Ç–∏ –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç.
                ValueError: –ï—Å–ª–∏ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ —Ñ–∞–π–ª–∞ –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è.
                Exception: –í —Å–ª—É—á–∞–µ –ª—é–±—ã—Ö –¥—Ä—É–≥–∏—Ö –æ—à–∏–±–æ–∫ –ø—Ä–∏ —á—Ç–µ–Ω–∏–∏ —Ñ–∞–π–ª–∞.
    
            –í—ã–≤–æ–¥–∏—Ç –≤ –∫–æ–Ω—Å–æ–ª—å —Å–æ–æ–±—â–µ–Ω–∏—è –æ –Ω–∞—á–∞–ª–µ –∑–∞–≥—Ä—É–∑–∫–∏, —É—Å–ø–µ—Ö–µ –∏ –æ—à–∏–±–∫–∞—Ö.
            """
            print(f"üîÑ –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö –∏–∑ —Ñ–∞–π–ª–∞: {path}")
            if not os.path.exists(path):
                print(f"‚ùå –§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {path}")
                raise FileNotFoundError(f"–§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {path}")
            try:
                if path.lower().endswith(".json"):
                    with open(path, 'r', encoding='utf-8') as f:
                       data = json.load(f)
                    df = pd.DataFrame(data).T
                    print(f"‚úÖ –î–∞–Ω–Ω—ã–µ —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω—ã –∏–∑ JSON, —Ñ–æ—Ä–º–∞: {df.shape}")
                    return df
                elif path.lower().endswith((".csv", ".txt")):
                    df = pd.read_csv(path)
                    print(f"‚úÖ –î–∞–Ω–Ω—ã–µ —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω—ã –∏–∑ CSV, —Ñ–æ—Ä–º–∞: {df.shape}")
                    return df
                else:
                    print(f"‚ùå –ù–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–π —Ñ–æ—Ä–º–∞—Ç —Ñ–∞–π–ª–∞: {path}")
                    raise ValueError(f"–ù–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–π —Ñ–æ—Ä–º–∞—Ç —Ñ–∞–π–ª–∞: {path}")
            except Exception as e:
                print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –¥–∞–Ω–Ω—ã—Ö –∏–∑ {path}: {e}")
                raise
    
        def save_data(self, df, path):
            """
            –°–æ—Ö—Ä–∞–Ω—è–µ—Ç pandas DataFrame –≤ —Ñ–∞–π–ª JSON –∏–ª–∏ CSV.
    
            –û–ø—Ä–µ–¥–µ–ª—è–µ—Ç —Ñ–æ—Ä–º–∞—Ç —Ñ–∞–π–ª–∞ –ø–æ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—é –∏ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–π –º–µ—Ç–æ–¥ pandas –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è DataFrame.
            –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç —Ñ–∞–π–ª—ã —Å —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—è–º–∏ .json, .csv –∏ .txt.
    
            –ê—Ä–≥—É–º–µ–Ω—Ç—ã:
                df (pandas.DataFrame): DataFrame, –∫–æ—Ç–æ—Ä—ã–π –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å.
                path (str): –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É, –≤ –∫–æ—Ç–æ—Ä—ã–π –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –¥–∞–Ω–Ω—ã–µ.
    
             –í—ã–∑—ã–≤–∞–µ—Ç:
                ValueError: –ï—Å–ª–∏ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ —Ñ–∞–π–ª–∞ –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è.
                Exception: –í —Å–ª—É—á–∞–µ –ª—é–±—ã—Ö –¥—Ä—É–≥–∏—Ö –æ—à–∏–±–æ–∫ –ø—Ä–∏ –∑–∞–ø–∏—Å–∏ —Ñ–∞–π–ª–∞.
    
            –í—ã–≤–æ–¥–∏—Ç –≤ –∫–æ–Ω—Å–æ–ª—å —Å–æ–æ–±—â–µ–Ω–∏—è –æ –Ω–∞—á–∞–ª–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è, —É—Å–ø–µ—Ö–µ –∏ –æ—à–∏–±–∫–∞—Ö.
            """
            print(f"üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –≤ —Ñ–∞–π–ª: {path}")
            try:
                if path.lower().endswith(".json"):
                    df.to_json(path)
                    print(f"‚úÖ –î–∞–Ω–Ω—ã–µ —É—Å–ø–µ—à–Ω–æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ JSON, —Ñ–æ—Ä–º–∞: {df.shape}")
                elif path.lower().endswith((".csv", ".txt")):
                    df.to_csv(path, index=False)
                    print(f"‚úÖ –î–∞–Ω–Ω—ã–µ —É—Å–ø–µ—à–Ω–æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ CSV, —Ñ–æ—Ä–º–∞: {df.shape}")
                else:
                    print(f"‚ùå –ù–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–π —Ñ–æ—Ä–º–∞—Ç —Ñ–∞–π–ª–∞: {path}")
                    raise ValueError(f"–ù–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–π —Ñ–æ—Ä–º–∞—Ç —Ñ–∞–π–ª–∞: {path}")
            except Exception as e:
                print(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö –≤ {path}: {e}")
                raise

–ö–ª–∞—Å—Å –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –æ–ø–µ—Ä–∞—Ü–∏–π –∑–∞–≥—Ä—É–∑–∫–∏ –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö –∏–∑ —Ñ–∞–π–ª–æ–≤ JSON –∏
CSV.

–ü—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è–µ—Ç –º–µ—Ç–æ–¥—ã –¥–ª—è —á—Ç–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö –∏–∑ —Ñ–∞–π–ª–æ–≤ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö —Ñ–æ—Ä–º–∞—Ç–æ–≤, —Ç–∞–∫–∏—Ö –∫–∞–∫
JSON –∏ CSV, –≤ pandas DataFrame, –∞ —Ç–∞–∫–∂–µ –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è DataFrame –æ–±—Ä–∞—Ç–Ω–æ –≤
—Ñ–∞–π–ª—ã JSON –∏–ª–∏ CSV.

–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è FileHandler.

–í—ã–≤–æ–¥–∏—Ç —Å–æ–æ–±—â–µ–Ω–∏–µ –≤ –∫–æ–Ω—Å–æ–ª—å –æ–± —É—Å–ø–µ—à–Ω–æ–π –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ FileHandler.

### Methods

` def load_data(self, path) `

     Expand source code
    
    
    def load_data(self, path):
        """
        –ó–∞–≥—Ä—É–∂–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –∏–∑ —Ñ–∞–π–ª–∞ JSON –∏–ª–∏ CSV –≤ pandas DataFrame.
    
        –û–ø—Ä–µ–¥–µ–ª—è–µ—Ç —Ç–∏–ø —Ñ–∞–π–ª–∞ –ø–æ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—é –∏ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–π –º–µ—Ç–æ–¥ pandas –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ –¥–∞–Ω–Ω—ã—Ö.
        –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç —Ñ–∞–π–ª—ã —Å —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—è–º–∏ .json, .csv –∏ .txt.
    
        –ê—Ä–≥—É–º–µ–Ω—Ç—ã:
            path (str): –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É, –∏–∑ –∫–æ—Ç–æ—Ä–æ–≥–æ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ –∑–∞–≥—Ä—É–∑–∏—Ç—å –¥–∞–Ω–Ω—ã–µ.
    
        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç:
            pandas.DataFrame: DataFrame, —Å–æ–¥–µ—Ä–∂–∞—â–∏–π –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ.
    
        –í—ã–∑—ã–≤–∞–µ—Ç:
            FileNotFoundError: –ï—Å–ª–∏ —Ñ–∞–π–ª –ø–æ —É–∫–∞–∑–∞–Ω–Ω–æ–º—É –ø—É—Ç–∏ –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç.
            ValueError: –ï—Å–ª–∏ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ —Ñ–∞–π–ª–∞ –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è.
            Exception: –í —Å–ª—É—á–∞–µ –ª—é–±—ã—Ö –¥—Ä—É–≥–∏—Ö –æ—à–∏–±–æ–∫ –ø—Ä–∏ —á—Ç–µ–Ω–∏–∏ —Ñ–∞–π–ª–∞.
    
        –í—ã–≤–æ–¥–∏—Ç –≤ –∫–æ–Ω—Å–æ–ª—å —Å–æ–æ–±—â–µ–Ω–∏—è –æ –Ω–∞—á–∞–ª–µ –∑–∞–≥—Ä—É–∑–∫–∏, —É—Å–ø–µ—Ö–µ –∏ –æ—à–∏–±–∫–∞—Ö.
        """
        print(f"üîÑ –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö –∏–∑ —Ñ–∞–π–ª–∞: {path}")
        if not os.path.exists(path):
            print(f"‚ùå –§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {path}")
            raise FileNotFoundError(f"–§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {path}")
        try:
            if path.lower().endswith(".json"):
                with open(path, 'r', encoding='utf-8') as f:
                   data = json.load(f)
                df = pd.DataFrame(data).T
                print(f"‚úÖ –î–∞–Ω–Ω—ã–µ —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω—ã –∏–∑ JSON, —Ñ–æ—Ä–º–∞: {df.shape}")
                return df
            elif path.lower().endswith((".csv", ".txt")):
                df = pd.read_csv(path)
                print(f"‚úÖ –î–∞–Ω–Ω—ã–µ —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω—ã –∏–∑ CSV, —Ñ–æ—Ä–º–∞: {df.shape}")
                return df
            else:
                print(f"‚ùå –ù–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–π —Ñ–æ—Ä–º–∞—Ç —Ñ–∞–π–ª–∞: {path}")
                raise ValueError(f"–ù–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–π —Ñ–æ—Ä–º–∞—Ç —Ñ–∞–π–ª–∞: {path}")
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –¥–∞–Ω–Ω—ã—Ö –∏–∑ {path}: {e}")
            raise

–ó–∞–≥—Ä—É–∂–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –∏–∑ —Ñ–∞–π–ª–∞ JSON –∏–ª–∏ CSV –≤ pandas DataFrame.

–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç —Ç–∏–ø —Ñ–∞–π–ª–∞ –ø–æ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—é –∏ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–π –º–µ—Ç–æ–¥ pandas
–¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ –¥–∞–Ω–Ω—ã—Ö. –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç —Ñ–∞–π–ª—ã —Å —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—è–º–∏ .json, .csv –∏ .txt.

–ê—Ä–≥—É–º–µ–Ω—Ç—ã: path (str): –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É, –∏–∑ –∫–æ—Ç–æ—Ä–æ–≥–æ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ –∑–∞–≥—Ä—É–∑–∏—Ç—å –¥–∞–Ω–Ω—ã–µ.

–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç: pandas.DataFrame: DataFrame, —Å–æ–¥–µ—Ä–∂–∞—â–∏–π –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ.

–í—ã–∑—ã–≤–∞–µ—Ç: FileNotFoundError: –ï—Å–ª–∏ —Ñ–∞–π–ª –ø–æ —É–∫–∞–∑–∞–Ω–Ω–æ–º—É –ø—É—Ç–∏ –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç.
ValueError: –ï—Å–ª–∏ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ —Ñ–∞–π–ª–∞ –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è. Exception: –í —Å–ª—É—á–∞–µ –ª—é–±—ã—Ö
–¥—Ä—É–≥–∏—Ö –æ—à–∏–±–æ–∫ –ø—Ä–∏ —á—Ç–µ–Ω–∏–∏ —Ñ–∞–π–ª–∞.

–í—ã–≤–æ–¥–∏—Ç –≤ –∫–æ–Ω—Å–æ–ª—å —Å–æ–æ–±—â–µ–Ω–∏—è –æ –Ω–∞—á–∞–ª–µ –∑–∞–≥—Ä—É–∑–∫–∏, —É—Å–ø–µ—Ö–µ –∏ –æ—à–∏–±–∫–∞—Ö.

` def save_data(self, df, path) `

     Expand source code
    
    
    def save_data(self, df, path):
        """
        –°–æ—Ö—Ä–∞–Ω—è–µ—Ç pandas DataFrame –≤ —Ñ–∞–π–ª JSON –∏–ª–∏ CSV.
    
        –û–ø—Ä–µ–¥–µ–ª—è–µ—Ç —Ñ–æ—Ä–º–∞—Ç —Ñ–∞–π–ª–∞ –ø–æ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—é –∏ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–π –º–µ—Ç–æ–¥ pandas –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è DataFrame.
        –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç —Ñ–∞–π–ª—ã —Å —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—è–º–∏ .json, .csv –∏ .txt.
    
        –ê—Ä–≥—É–º–µ–Ω—Ç—ã:
            df (pandas.DataFrame): DataFrame, –∫–æ—Ç–æ—Ä—ã–π –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å.
            path (str): –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É, –≤ –∫–æ—Ç–æ—Ä—ã–π –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –¥–∞–Ω–Ω—ã–µ.
    
         –í—ã–∑—ã–≤–∞–µ—Ç:
            ValueError: –ï—Å–ª–∏ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ —Ñ–∞–π–ª–∞ –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è.
            Exception: –í —Å–ª—É—á–∞–µ –ª—é–±—ã—Ö –¥—Ä—É–≥–∏—Ö –æ—à–∏–±–æ–∫ –ø—Ä–∏ –∑–∞–ø–∏—Å–∏ —Ñ–∞–π–ª–∞.
    
        –í—ã–≤–æ–¥–∏—Ç –≤ –∫–æ–Ω—Å–æ–ª—å —Å–æ–æ–±—â–µ–Ω–∏—è –æ –Ω–∞—á–∞–ª–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è, —É—Å–ø–µ—Ö–µ –∏ –æ—à–∏–±–∫–∞—Ö.
        """
        print(f"üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –≤ —Ñ–∞–π–ª: {path}")
        try:
            if path.lower().endswith(".json"):
                df.to_json(path)
                print(f"‚úÖ –î–∞–Ω–Ω—ã–µ —É—Å–ø–µ—à–Ω–æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ JSON, —Ñ–æ—Ä–º–∞: {df.shape}")
            elif path.lower().endswith((".csv", ".txt")):
                df.to_csv(path, index=False)
                print(f"‚úÖ –î–∞–Ω–Ω—ã–µ —É—Å–ø–µ—à–Ω–æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ CSV, —Ñ–æ—Ä–º–∞: {df.shape}")
            else:
                print(f"‚ùå –ù–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–π —Ñ–æ—Ä–º–∞—Ç —Ñ–∞–π–ª–∞: {path}")
                raise ValueError(f"–ù–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–π —Ñ–æ—Ä–º–∞—Ç —Ñ–∞–π–ª–∞: {path}")
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö –≤ {path}: {e}")
            raise

–°–æ—Ö—Ä–∞–Ω—è–µ—Ç pandas DataFrame –≤ —Ñ–∞–π–ª JSON –∏–ª–∏ CSV.

–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç —Ñ–æ—Ä–º–∞—Ç —Ñ–∞–π–ª–∞ –ø–æ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—é –∏ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–π –º–µ—Ç–æ–¥
pandas –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è DataFrame. –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç —Ñ–∞–π–ª—ã —Å —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—è–º–∏ .json, .csv
–∏ .txt.

–ê—Ä–≥—É–º–µ–Ω—Ç—ã: df (pandas.DataFrame): DataFrame, –∫–æ—Ç–æ—Ä—ã–π –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å.
path (str): –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É, –≤ –∫–æ—Ç–æ—Ä—ã–π –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –¥–∞–Ω–Ω—ã–µ.

–í—ã–∑—ã–≤–∞–µ—Ç: ValueError: –ï—Å–ª–∏ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ —Ñ–∞–π–ª–∞ –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è. Exception: –í
—Å–ª—É—á–∞–µ –ª—é–±—ã—Ö –¥—Ä—É–≥–∏—Ö –æ—à–∏–±–æ–∫ –ø—Ä–∏ –∑–∞–ø–∏—Å–∏ —Ñ–∞–π–ª–∞.

–í—ã–≤–æ–¥–∏—Ç –≤ –∫–æ–Ω—Å–æ–ª—å —Å–æ–æ–±—â–µ–Ω–∏—è –æ –Ω–∞—á–∞–ª–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è, —É—Å–ø–µ—Ö–µ –∏ –æ—à–∏–±–∫–∞—Ö.

  * ### Super-module

    * `[src](index.html "src")`
  * ### Classes

    * #### `DataCleaner`

      * `clean_data`
    * #### `FileHandler`

      * `load_data`
      * `save_data`

Generated by [pdoc 0.11.5](https://pdoc3.github.io/pdoc "pdoc: Python API
documentation generator").

